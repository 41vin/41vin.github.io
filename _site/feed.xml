<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-07-04T17:15:03+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Escape Diary</title><subtitle>From the master's program to the doctoral program, there were many moments during my time in post-graduate school when I wanted to escape. However, it seems to have been the most significant turning point in my life. Enjoy reading :)
</subtitle><author><name>Geon Kim</name><email>gun@khu.ac.kr</email></author><entry><title type="html">Intent-Aware Radio Resource Scheduling in a RAN Slicing Scenario Using Reinforcement Learning</title><link href="http://localhost:4000/blog/paper/2024-07-03-Intent-Aware-Radio-Resource-Scheduling-in-a-RAN-Slicing-Scenario-Using-Reinforcement-Learning/" rel="alternate" type="text/html" title="Intent-Aware Radio Resource Scheduling in a RAN Slicing Scenario Using Reinforcement Learning" /><published>2024-07-03T00:00:00+09:00</published><updated>2024-07-03T00:00:00+09:00</updated><id>http://localhost:4000/blog/paper/Intent-Aware-Radio-Resource-Scheduling-in-a-RAN-Slicing-Scenario-Using-Reinforcement-Learning</id><content type="html" xml:base="http://localhost:4000/blog/paper/2024-07-03-Intent-Aware-Radio-Resource-Scheduling-in-a-RAN-Slicing-Scenario-Using-Reinforcement-Learning/"><![CDATA[<p class="note" title="Keywords">Radio resource scheduling, RAN slicing, intent-aware sheduling, reinforcement learning</p>

<ul id="markdown-toc">
  <li><a href="#1-why-this-paper" id="markdown-toc-1-why-this-paper">1. Why this paper</a></li>
  <li><a href="#2-summary-of-paper" id="markdown-toc-2-summary-of-paper">2. Summary of paper</a>    <ul>
      <li><a href="#21-introduction" id="markdown-toc-21-introduction">2.1 Introduction</a></li>
    </ul>
  </li>
  <li><a href="#3-take-away" id="markdown-toc-3-take-away">3. Take Away</a></li>
</ul>

<h1 id="1-why-this-paper">1. Why this paper</h1>
<ul>
  <li>머신러닝을 활용한 RAN Slicing 프레임워크 이해</li>
  <li><code class="language-plaintext highlighter-rouge">Intent-driven</code> 개념 설명</li>
  <li>Simulation 코드가 존재함</li>
</ul>

<hr />

<h1 id="2-summary-of-paper">2. Summary of paper</h1>

<h2 id="21-introduction">2.1 Introduction</h2>

<p>5G 시스템은 서로 다른 <code class="language-plaintext highlighter-rouge">network slice</code>의 구성과 구조를 slice들의 요구에 맞춰 배치할 수 있고 기능들을 online으로 바꿀 수 있다.</p>

<p class="note">End-to-end network slicing: RAN + Transport network + Core network</p>

<ul>
  <li>
    <p><code class="language-plaintext highlighter-rouge">inter-slice scheduling</code>: <code class="language-plaintext highlighter-rouge">RAN slicing</code>의 기능 중 하나는 slice 인스턴스들간의 무선 자원들을 배치하는 Radio Resource Scheduling(RRS)를 배포하는 것이다.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">intra-slice scheduling</code>: 다른 RRS는 slice 인스턴스 내에 있는 자원들을 담당한다.</p>
  </li>
</ul>

<p>위에서 설명한 inter, intra-slice RRS scheduler들은 반드시 slice들의 intent들을 만족시키며 무선 자원을 분산시켜야 한다.</p>

<p>새로운 RRS는 아래의 조건들을 만족시켜야 한다.</p>

<ol>
  <li>서로 다른 slice 종류들의 다른 요구사항들을 만족시킬 것</li>
  <li>각 slice에 충분한 무선 자원을 제공하여 네트워크 intent를 만족시킬 것</li>
  <li>모든 slice들의 요구사항을 만족시킬만큼의 무선 자원이 없을 때, 가장 중요한 slice intent를 우선시할 것</li>
</ol>

<p>RAN은 데이터가 풍부한 환경을 가지고 있기 때문에 <code class="language-plaintext highlighter-rouge">data-driven</code> 접근법이 큰 각광을 받고 있다. 특히, 강화학습은 환경에 상관없이 유연한 결정을 정책을 실현시킬 수 있어 큰 주목을 받고 있다.</p>

<p>알고리즘만큼 중요한 것이 <code class="language-plaintext highlighter-rouge">Autonomous RRS system</code>이다. <code class="language-plaintext highlighter-rouge">Autonomous RRS system</code>은 서로 다른 slice들로부터의 요구사항들을 만족시킬 수 있다. 특히 본 논문은 <code class="language-plaintext highlighter-rouge">TM Forum</code>에서 정의한 네트워크 요구사항들을 이용해 intent를 구체화시키고 있다.</p>

<p>RRS는 다른 슬라이스 intent들을 받고 네트워크가 이 intent들을 만족시킬 수 있게 변화시켜야 한다.</p>

<p class="note">본 논문은 강화학습을 사용한 RAN slicing을 위한 intent-aware RRS를 제안하고 있다. 이 RRS는 서로 다른 slice 종류들과 QoS intent(throughput, latency, 그리고 packet loss rate에 기반한)를 사용한다.</p>

<p>저자가 제안하는 방법을 크게 나눠보면</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">inter-slice</code> allocation: RL agent</li>
  <li><code class="language-plaintext highlighter-rouge">intra-slice</code> allocation: RRS가 <code class="language-plaintext highlighter-rouge">round-robin</code> 스케쥴러를 이용</li>
</ol>

<p>으로 정리할 수 있다.</p>

<p>RL agent는</p>
<ol>
  <li>slice들의 intent들을 만족시킬 수 있는 RRS의 action들</li>
  <li>SLA에 정의되어 있는 weight들에 따라 slice intent의 priority를</li>
</ol>

<p>학습한다.</p>

<hr />

<h1 id="3-take-away">3. Take Away</h1>

<ul>
  <li>논문에서 사용한 채널 시뮬레이터 <code class="language-plaintext highlighter-rouge">QuaDRiGa</code> 대신 ns-3로 구현해보기</li>
</ul>]]></content><author><name>Geon Kim</name><email>gun@khu.ac.kr</email></author><category term="paper" /><category term="ieee" /><summary type="html"><![CDATA[**Authors**: Sihem Bakri et al.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/ran-slicing/RAN-AI.png" /><media:content medium="image" url="http://localhost:4000/assets/img/blog/ran-slicing/RAN-AI.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Toward Smaller and Lower-Cost 5G Devices with Longer Battery Life - An Overview of 3GPP Release 17 RedCap</title><link href="http://localhost:4000/blog/paper/2024-07-01-Overview-of-3GPP-Release-17-RedCap-copy/" rel="alternate" type="text/html" title="Toward Smaller and Lower-Cost 5G Devices with Longer Battery Life - An Overview of 3GPP Release 17 RedCap" /><published>2024-07-01T00:00:00+09:00</published><updated>2024-07-01T00:00:00+09:00</updated><id>http://localhost:4000/blog/paper/Overview-of-3GPP-Release-17-RedCap%20copy</id><content type="html" xml:base="http://localhost:4000/blog/paper/2024-07-01-Overview-of-3GPP-Release-17-RedCap-copy/"><![CDATA[<p class="note" title="Keywords">RedCap, 5G, NR</p>

<ul id="markdown-toc">
  <li><a href="#1-why-this-paper" id="markdown-toc-1-why-this-paper">1. Why this paper</a></li>
  <li><a href="#2-summary-of-paper" id="markdown-toc-2-summary-of-paper">2. Summary of paper</a>    <ul>
      <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
      <li><a href="#use-cases-and-requirements" id="markdown-toc-use-cases-and-requirements">Use Cases and Requirements</a></li>
      <li><a href="#reduced-device-capabilities" id="markdown-toc-reduced-device-capabilities">Reduced Device Capabilities</a></li>
      <li><a href="#battery-lifetime-enhancement" id="markdown-toc-battery-lifetime-enhancement">Battery Lifetime Enhancement</a>        <ul>
          <li><a href="#a-extended-drx-for-rrc-idle-and-inactive-states" id="markdown-toc-a-extended-drx-for-rrc-idle-and-inactive-states">A. Extended DRX for RRC idle and inactive states</a></li>
          <li><a href="#b-rrm-relaxation-for-stationary-devices" id="markdown-toc-b-rrm-relaxation-for-stationary-devices">B. RRM relaxation for stationary devices</a></li>
        </ul>
      </li>
      <li><a href="#coexistence-coverage-and-capacity-impacts" id="markdown-toc-coexistence-coverage-and-capacity-impacts">Coexistence, coverage, and capacity impacts</a>        <ul>
          <li><a href="#a-coexistence-with-other-nr-devices" id="markdown-toc-a-coexistence-with-other-nr-devices">A. Coexistence with other NR devices</a></li>
          <li><a href="#b-coverage-impacts" id="markdown-toc-b-coverage-impacts">B. Coverage impacts</a></li>
          <li><a href="#capacity-imapcts" id="markdown-toc-capacity-imapcts">Capacity imapcts</a></li>
        </ul>
      </li>
      <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
    </ul>
  </li>
  <li><a href="#3-take-away" id="markdown-toc-3-take-away">3. Take Away</a></li>
</ul>

<h1 id="1-why-this-paper">1. Why this paper</h1>
<ul>
  <li>3GPP Release 17에 정의되어 있는 RedCap 심층조사</li>
  <li>RedCap을 포함한 RAN Simulator 개발에 필요</li>
</ul>

<hr />

<h1 id="2-summary-of-paper">2. Summary of paper</h1>

<h2 id="introduction">Introduction</h2>
<ul>
  <li>RedCap use cases는 wearables, industrial wireless sensors, 그리고 video surveillance를 포함한다.</li>
  <li>이러한 use case들을 지원하기 위해, eMBB, URLLC, 그리고 mMTC 사이에 있는 use case들을 지원하기 위해 3GPP는 RedCap NR Device들을 정의하였다.</li>
  <li>본 논문은 3GPP 표준 시점에서의 RedCap에 대한 overview를 제공한다.</li>
</ul>

<h2 id="use-cases-and-requirements">Use Cases and Requirements</h2>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Wearables</th>
      <th>Industrial wireless sensors</th>
      <th>Video surveillance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Data rate</strong> (Reference bit rate)</td>
      <td>5-50 Mbps in DL and 2-5 Mbps in UL*</td>
      <td>2 Mbps</td>
      <td>2-4 Mbps for economic video<br />7.5-25 Mbps for high-end video</td>
    </tr>
    <tr>
      <td><strong>Latency</strong></td>
      <td>-</td>
      <td>100 ms</td>
      <td>500 ms</td>
    </tr>
    <tr>
      <td><strong>Availability/reliability</strong></td>
      <td>-</td>
      <td>99.99%</td>
      <td>99%-99.9%</td>
    </tr>
    <tr>
      <td><strong>Device battery lifetime</strong></td>
      <td>At least few days and up to 1-2 weeks</td>
      <td>At least few years</td>
      <td>-</td>
    </tr>
    <tr>
      <td><strong>Traffic pattern</strong></td>
      <td>-</td>
      <td>UL heavy</td>
      <td>UL heavy</td>
    </tr>
    <tr>
      <td><strong>Stationarity</strong></td>
      <td>Non-stationary</td>
      <td>Stationary</td>
      <td>Stationary</td>
    </tr>
  </tbody>
</table>

<p class="note">Peak bit rate for wearables can be up to 150 Mbps in DL and 50 Mbps in UL.</p>

<p>명확하게 말하자면, data rate와 latency는 NR eMBB/URLLC 만큼 높지 않고, 요구 배터리 수명은 mMTC만큼 길지 않다.</p>

<p>위의 세 가지 usecase들을 하나의 RedCap에서 지원하는 것이 바람직하다.</p>

<p><img src="/assets/img/blog/RedCap2/Figure1.png" alt="Figure1" /></p>

<p>RedCap은 TR 38.875에서 정의되어있다.</p>

<h2 id="reduced-device-capabilities">Reduced Device Capabilities</h2>
<p>Release 17 RedCa work item으로 다음과 같은 항목들이 정의되었다.</p>
<ul>
  <li>Reduction of maximum device bandwidth</li>
  <li>Reduction of minimum antenna configuration at the device</li>
  <li>Reduction of minimum supported number of DL MIMO layers</li>
  <li>Relaxed maximum DL modulation order</li>
  <li>Support for half-duplex operation in FDD bands</li>
</ul>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>FR1 bands</th>
      <th>FR2 bands</th>
      <th> </th>
      <th> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td> </td>
      <td>Reference device</td>
      <td>RedCap device</td>
      <td>Reference device</td>
      <td>RedCap device</td>
    </tr>
    <tr>
      <td>Maximum device bandwidth</td>
      <td>100 MHz</td>
      <td>20 MHz</td>
      <td>200 MHz</td>
      <td>100 MHz</td>
    </tr>
    <tr>
      <td>Minimum antenna configuration¹</td>
      <td>2 or 4 receiver branches</td>
      <td>2 receiver branches</td>
      <td>2 antenna panels, each supporting 4 dual polarized antenna elements</td>
      <td>2 antenna panels, each supporting 4 dual polarized antenna elements</td>
    </tr>
    <tr>
      <td>Minimum supported number of DL MIMO layers</td>
      <td>2 or 4</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Maximum DL modulation order</td>
      <td>256QAM</td>
      <td>64QAM</td>
      <td>64QAM</td>
      <td>64QAM</td>
    </tr>
    <tr>
      <td>Duplex operation</td>
      <td>TDD or full-duplex FDD</td>
      <td>TDD or half-duplex FDD</td>
      <td>TDD</td>
      <td>TDD</td>
    </tr>
    <tr>
      <td>Cost reduction</td>
      <td>0%</td>
      <td>~65%</td>
      <td>0%</td>
      <td>~50%</td>
    </tr>
  </tbody>
</table>

<p>¹ In 3GPP the requirements on physical antenna implementation at the device are not specified for FR1 and FR2. However, the effective isotropic radiated power, the effective isotropic receiver sensitivity, and the spherical coverage requirements specified for different power classes in FR2 implicitly impose requirements on the actual antenna implementation. The minimum antenna configuration for the reference device indicated in this table assumes power class 3 [6]. Both NR devices and RedCap devices may support a different power class with different set of requirements. The reference device and RedCap device support the same minimum number of receiver branches in FR2.</p>

<p>위의 표에 나열되어 있는 기능을 만족하면 상당한 비용 절감 효과를 얻을 수 있으며, 동시에 성능, 사양 및 공존(기기 간의 상호 간섭 등)에 미치는 영향은 관리 가능하다.</p>

<p>하지만 RedCap UE는</p>
<ol>
  <li>FR1/FR2에서 20/100MHz 보다 넓은 주파수 대역</li>
  <li>Carrier aggregation</li>
  <li>Dual connectivity</li>
  <li>2 device receiver/transmitter branches</li>
  <li>2 DL/UL MIMO 레이어들</li>
</ol>

<p>을 사용할 수 없다.</p>

<p>또한, Higher 레이어들에서의 제약사항들은 다음과 같다.</p>
<ol>
  <li>Data Radio Bearer(DRB) 수 감소: 기기가 필수적으로 지원해야 하는 DRB의 최대 수를 16개에서 8개로 감소</li>
  <li>Sequence Number(SN) 길이 감소: PDU에서 PDCP 및 RLC 계층의 acknowledged 모드에 대한 SN 길이를 18비트에서 12비트로 감소</li>
  <li>Automatic Neighbor Relation(ANR) 기능 비활성화: SON의 기능인 ANR 기능 지원이 필수 사항에서 제외</li>
</ol>

<h2 id="battery-lifetime-enhancement">Battery Lifetime Enhancement</h2>
<p>아래의 기술들은 RedCap 기기에서 배터리 수명을 늘리기 위해 사용하는 기법들이다.</p>

<h3 id="a-extended-drx-for-rrc-idle-and-inactive-states">A. Extended DRX for RRC idle and inactive states</h3>
<p class="note">Discontinuous reception(DRX) mechanism: NR 릴리즈 15에서 소개되었고 디바이스가 inactive 기간에서 <code class="language-plaintext highlighter-rouge">sleep</code> 모드로 설정된다.</p>

<p>일반적인 NR에서 DRX cycle의 최댓값은 2.56초이다. 하지만 RedCap use case에서는 eMBB/URLLC 만큼의 tight 혹은 deterministic한 latency 요구사항이 필요하지 않다.</p>

<p>따라서 extended DRX(eDRX)에서는 10485.76초까지 RRC <code class="language-plaintext highlighter-rouge">idle state</code> 그리고 <code class="language-plaintext highlighter-rouge">inactive state</code>는 10.24초까지 정의되었다.</p>

<p><img src="/assets/img/blog/RedCap2/Figure2.png" alt="Figure2" /></p>
<ul>
  <li>IAT: Inter-Arrival Times</li>
</ul>

<p>위의 그림은 다른 eDRX를 가지고 있을 때 battery 수명 증가를 그래프로 그린 것이다.</p>

<h3 id="b-rrm-relaxation-for-stationary-devices">B. RRM relaxation for stationary devices</h3>
<p><code class="language-plaintext highlighter-rouge">idle</code>과 <code class="language-plaintext highlighter-rouge">inactive</code>일 때 RSRP와 RSRQ에 기반한 RRM measurement는 serving cell과 neighbor cell들로부터 측정된다. 이러한 measurement들은 최적의 신호 quality를 달성하는데 도움은 되지만 데이터를 전송하지 않을 때 battery를 많이 소모하게 된다.</p>

<p>Rel 16에서 low-mobility, not-at-cell-edge 시나리오에 대한 neighbor cell RRM measurements relaxation이 소개되었다.</p>

<p>Rel 17에서는 네트워크가 RRC 연결 상태의 장치에 대해 RSRP/RSRQ 기반의 정지 조건을 추가로 구성할 수 있다. 디바이스는 네트워크에 이 조건이 만족할 때와 만족하지 않을 때를 보고해야 한다.</p>

<h2 id="coexistence-coverage-and-capacity-impacts">Coexistence, coverage, and capacity impacts</h2>

<h3 id="a-coexistence-with-other-nr-devices">A. Coexistence with other NR devices</h3>
<p>RedCap과 다른 NR 디바이스간의 coexistence는 RedCap work item의 중요한 목표이다.
Coexistence에 다음 두 가지 challenge들이 존재한다.</p>

<ol>
  <li>Identification of RedCap devices
    <ul>
      <li>NR 장치가 RedCap인지 여부는 Random Access 절차 완료 후 네트워크에 알려지므로, 초기에 모든 장치가 가장 최소한의 기능을 가진 것으로 간주하고 스케쥴링 해야 한다.</li>
      <li>RedCap 장치는 기능이 축소된 장치이므로, 네트워크가 이 장치를 기준으로 스케쥴링하면 일반 NR 장치도 그에 맞춰 제한적으로 동작하게 된다.</li>
      <li>이로 인해 네트워크 자원이 비효율적으로 사용된다.</li>
      <li>해결책: 네트워크가 Random Access 절차 중 장치가 RedCap 장치인지 아닌지를 미리 알 수 있게하는 방법이 도입됨.
        <ul>
          <li>Message 1: RedCap 전용 PRACH 리소스가 셀에 구성된 경우</li>
          <li>Message 3: Random access 절차에서 Common Control Channel(CCCH)에 RedCap 전용 논리 채널 ID 값을 포함</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Avoidance of PUSCH resource fragmentation
<img src="/assets/img/blog/RedCap2/Figure3.png" alt="Figure3" /></li>
</ol>

<p>일반 NR 장치에 대해 구성된 initial BWP는 너무 넓을 수 있어 Release 17에서는 별도의 RedCap 전용 초기 UL 및 DL BWP 구성을 지원한다. 그러나 RedCap 전용 UL과 DL의 BWP가 carrier center frequency 근처에 배치되면, RedCap 장치의 POUCCH 전송이 다른 장치의 PUSCH 자원 단편화를 유발할 수 있다.</p>

<p>이를 해결하기 위해 Release 17에서 RedCap 장치의 별도의 초기 UL BWP에서 PUCCH 주파수 호핑 비활성화를 지원하며, SSB 및 CORESET #0 없이 별도의 초기 DL BWP를 지원한다.</p>

<p>BWP configuration 주요 사항</p>

<ul>
  <li>RedCap configuration 결정 요소
    <ul>
      <li>Carrier bandwidth</li>
      <li>최대 데이터 속도 요구사항</li>
      <li>장치 능력</li>
      <li>트래픽 활동</li>
    </ul>
  </li>
</ul>

<p>이 요소들을 고려하여 네트워크는 RedCap 장치에 적합한 UL/DL BWP 위치를 결정할 수 있다.</p>

<ul>
  <li>신호 오버헤드 관점
    <ul>
      <li>RedCap과 일반 NR 장치 간에 BWP 구성을 공유하는 것이 바람직하다.
        <ul>
          <li>두 종류 장치 모두 동일한 BWP 설정을 사용하게 되어, 별도의 BWP 설정을 추가할 필요가 없다.</li>
          <li>DL BWP 공유
            <ul>
              <li>RedCap 장치와 일반 NR 장치가 공유하는 DL BWP를 사용하면, 추가적인 BWP 설정이나 추가 SSB를 전송할 필요가 없다.
                <ul>
                  <li>SSB는 기지국과 장치 간의 초기 통신을 설정하는데 사용되는 신호로, 추가 SSB 전송이 필요 없으면 네트워크의 신호량이 줄어든다.</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>위에서 설명한 개선 사항을 제외하고도 CSP가 SIB1에서 indication을 통해 RedCap 장치가 cell carrier에 접근하지 못할 수 있는 기능을 표준에서 정의하였다. 이는 네트워크 과부화 상황에서 셀 내 다른 NR 장치에 사용할 수 있는 무선 자원을 우선적으로 제공하거나, RedCap 장치의 접근이 다른 장치의 성능에 영향을 미칠 수 있다 의심되는 경우에 유용하다.</p>

<h3 id="b-coverage-impacts">B. Coverage impacts</h3>

<p>Reduced capabilities는 디바이스의 커버리지에 영향을 미칠 수 있다. 안테나 사이즈와 대역폭의 감소가 coverage에 가장 큰 영향을 미치게 된다. Coverage에 미치는 영향을 평가하는 것도 study item 중 하나이다. 평가는 link budget analysis를 통해 이루어진다.</p>

<p>Message 1 (PRACH), Message 2 (PDSCH), Message 3 (PUSCH), and Message 4 (PDSCH), PUCCH, and the PDCCH scheduling Message 2/4 on common search space 모두 link budget analysis에 포함된다. 또한 analysis는 시골이나 도심지역에서 FR1, FR2를 가정한 다양한 환경에서 진행된다.</p>

<p>Link budget analysis에서 사용되는 metric</p>
<ul>
  <li>Maximum Isotropic Loss (MIL): 기지국과 디바이스에서의 path loss와 beamforming gain을 포착</li>
</ul>

<p>만약 reference device의 lowest MIL보다 RedCap 디바이스의 MIL이 낮다면 coverage recovery가 상응하는 channel에 필요하다.이 때, Reference device의 lowerst MIL과 RedCap 디바이스의 MIL 차이만큼 coverage recovery가 필요하다.</p>

<p>Link budget analysis 결과는 다음과 같이 요악할 수 있다.</p>
<ul>
  <li>UL(FR1 &amp; FR2)
    <ul>
      <li>FR1과 FR2의 UL에서 coverage recovery 필요없음</li>
    </ul>
  </li>
  <li>DL (FR1)
    <ul>
      <li>Urban micro 시나리오
        <ul>
          <li>RedCap 장치가 1개의 수신기 branch(antenna)를 가진 경우 Message 2에 대해 커버리지 회복 필요</li>
          <li>2개의 수신기 브랜치를 가진 경우 커버리지 회복이 필요하지 않음</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>DL (FR2)
    <ul>
      <li>Coverage 회복 필요 여부는 RedCap 및 참조 장치의 maximum transmitted radiated power(TRP) 선택에 따라 다름</li>
      <li>TRP 23 dBm 가정 시:
        <ul>
          <li>Message 2, Message 4, PDSCH와 같은 일부 DL 채널에 대해 커버리지 회복 필요</li>
        </ul>
      </li>
      <li>TRP 12 dBM 가정 시:
        <ul>
          <li>DL 채널에 대해 커버리지 회복 필요하지 않음</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>이 때 커버리지 회복에 대해 쓰이는 기술은 Rel 15/16에서 쓰이는 기술들을 최대한 활용한다.</p>

<h3 id="capacity-imapcts">Capacity imapcts</h3>
<p>RedCap 기기의 lower capability는 시스템 성능에 악영향을 준다. 이를 평가하기 위해 3GPP에서 SLS를 수행하였다.
<img src="/assets/img/blog/RedCap2/Figure4.png" alt="Figure4" /></p>

<p>Figure 4는 FR1에서 1개의 수신기 branch를 가진 RedCap 장치의 비율이 증가하는 경우(0% - 90%)에 따른 셀 load에 대한 eMBB 사용자들의 DL 사용자 처리량을 보여준다.</p>

<p>그림에서 볼 수 있듯이 채널 상태가 좋은 eMBB 유저들은 RedCap 유저들이 증가해도 크게 영향을 받지 않는다. 중간에 있는 유저들은 RedCap 유저들이 증가할수록 throughput이 감소하는 것을 확인할 수 있다. 이는 RedCap 장치가 스펙트럼 효율이 낮아 주어진 load에서 더 많은 자원을 사용하기 때문이다.</p>

<ul>
  <li>트래픽 모델링
    <ul>
      <li>eMBB users: \(2 * 10^7\) bit/s (200ms 마다 0.5MB 전송)</li>
      <li>RedCap users: \(4 * 10^5\) bit.s (2초마다 0.1MB 전송)</li>
      <li>RedCap user의 부하는 eMBB 사용자의 부하보다 50배 낮음</li>
    </ul>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>
<p>본 논문은 3GPP 표준에서 어떻게 RedCap을 디자인하는지에 대한 overview를 제공하고 있다. 또한 RedCap과 다른 NR 디바이스들의 coexistence를 어떻게 표준이 실현시켰는지 보여주고 있다. 또한 Release 18의 RedCap도 Release 17 기반으로 강화될 것으로 예상한다. RedCap의 발전으로 Release 17 usecase에 대해 향상된 지원을 제공할 뿐 아니라, smart grid와 같은 새로운 usecase 세그먼트로의 확장을 지원할 수 있다.</p>

<h1 id="3-take-away">3. Take Away</h1>
<ul>
  <li>Simulator 구성 시 필요한 metric</li>
  <li>RedCap이 프로토콜이 아닌 device의 한 종류란 것</li>
</ul>]]></content><author><name>Geon Kim</name><email>gun@khu.ac.kr</email></author><category term="paper" /><category term="ieee" /><summary type="html"><![CDATA[**Authors**: Sandeep Narayanan Kadan Veedu et al.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/RedCap/RedCap-Usecases.png" /><media:content medium="image" url="http://localhost:4000/assets/img/blog/RedCap/RedCap-Usecases.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Research on 5G RedCap Standard and Key Technologies</title><link href="http://localhost:4000/blog/paper/2024-06-28-Research-on-5G-RedCap-Standard-and-Key-copy/" rel="alternate" type="text/html" title="Research on 5G RedCap Standard and Key Technologies" /><published>2024-06-28T00:00:00+09:00</published><updated>2024-06-28T00:00:00+09:00</updated><id>http://localhost:4000/blog/paper/Research-on-5G-RedCap-Standard-and-Key%20copy</id><content type="html" xml:base="http://localhost:4000/blog/paper/2024-06-28-Research-on-5G-RedCap-Standard-and-Key-copy/"><![CDATA[<p class="note" title="Keywords">RedCap, 5G, NR</p>

<ul id="markdown-toc">
  <li><a href="#1-why-this-paper" id="markdown-toc-1-why-this-paper">1. Why this paper</a></li>
  <li><a href="#2-summary-of-paper" id="markdown-toc-2-summary-of-paper">2. Summary of paper</a>    <ul>
      <li><a href="#rel-17-standardization-work-on-redcap-ue" id="markdown-toc-rel-17-standardization-work-on-redcap-ue">REL-17 Standardization Work on RedCap UE</a>        <ul>
          <li><a href="#a-use-case-specific-requirements" id="markdown-toc-a-use-case-specific-requirements">A. Use Case Specific Requirements</a></li>
          <li><a href="#b-objectives-of-rel-17-w1-on-redcap-ue" id="markdown-toc-b-objectives-of-rel-17-w1-on-redcap-ue">B. Objectives of Rel-17 W1 on RedCap UE</a></li>
        </ul>
      </li>
      <li><a href="#key-characteristics-and-analysis-for-rel-17-redcap-ue" id="markdown-toc-key-characteristics-and-analysis-for-rel-17-redcap-ue">Key Characteristics and Analysis for REL-17 RedCap UE</a>        <ul>
          <li><a href="#a-reduced-redcap-ue-bandwidth" id="markdown-toc-a-reduced-redcap-ue-bandwidth">A. Reduced RedCap Ue Bandwidth</a></li>
          <li><a href="#b-collison-resolutions-in-half-duplex-mode" id="markdown-toc-b-collison-resolutions-in-half-duplex-mode">B. Collison Resolutions in Half-duplex Mode</a></li>
          <li><a href="#c-early-indication" id="markdown-toc-c-early-indication">C. Early Indication</a></li>
          <li><a href="#d-energy-saving" id="markdown-toc-d-energy-saving">D. Energy Saving</a></li>
        </ul>
      </li>
      <li><a href="#analysis-and-solutions-for-coexistence-problems" id="markdown-toc-analysis-and-solutions-for-coexistence-problems">Analysis and Solutions for Coexistence Problems</a></li>
      <li><a href="#rel-18-redcap-ue-evolution" id="markdown-toc-rel-18-redcap-ue-evolution">Rel-18 RedCap UE Evolution</a></li>
    </ul>
  </li>
  <li><a href="#3-take-away" id="markdown-toc-3-take-away">3. Take Away</a></li>
</ul>

<h1 id="1-why-this-paper">1. Why this paper</h1>
<ul>
  <li>Network Slicing 논문의 구성요소인 RedCap 조사</li>
</ul>

<h1 id="2-summary-of-paper">2. Summary of paper</h1>

<h2 id="rel-17-standardization-work-on-redcap-ue">REL-17 Standardization Work on RedCap UE</h2>

<p>본 파트에서는 Rel-17 RecCap UE의 요구사항을 설명한다.</p>

<h3 id="a-use-case-specific-requirements">A. Use Case Specific Requirements</h3>

<p>Rel-17 RedCap UE는 세 개의 main usecase가 정의되어 있다.</p>

<ul>
  <li>
    <p>Industrial wireless sensors</p>
  </li>
  <li>Video surveillance</li>
  <li>Smart wearable devices</li>
</ul>

<p><img src="/assets/img/blog/RedCap/Table1.png" alt="Table1" /></p>

<h3 id="b-objectives-of-rel-17-w1-on-redcap-ue">B. Objectives of Rel-17 W1 on RedCap UE</h3>

<ol>
  <li>UE complexity reduction features</li>
</ol>

<ul>
  <li><strong>UE bandwidth</strong>
    <ul>
      <li>Maximum UE 대역폭이 FR1에서 20MHz, FR2에서 100MHz로 감소</li>
      <li>UE 대역폭을 감소시킨 RedCap UE와 normal UE의 coexistence가 특정 시나리오에서 system performance에 영향을 미칠 것임</li>
    </ul>
  </li>
  <li><strong>Number of receiving antennas</strong>
    <ul>
      <li>최소한의 Rx 안테나수(1개)가 NR RedCap에서 허용됨</li>
      <li>UE의 complexity가 감소될 것으로 예상</li>
    </ul>
  </li>
  <li><strong>Number of DL MIMO Layers</strong>
    <ul>
      <li>1 Rx를 가지고 있는 RedCap UE에게 1 DL MIMO layer 지원</li>
      <li>2 RX를 가지고 있는 RedCap UE는 2 DL MIMO layer 지원</li>
    </ul>
  </li>
  <li><strong>Modulation order</strong>
    <ul>
      <li>FR1 DL에서 256QAM을 필수로 사용하는 것이 아닌 선택 사항으로 허용 (RedCap UE를 보다 유연하게 구현 가능)</li>
    </ul>
  </li>
  <li><strong>Duplex mode</strong>
    <ul>
      <li>목표는 Rel-15/16의 기존 프로토콜을 활용하여 사양에 미치는 영향을 최소화 하는 것임</li>
      <li>RedCap UE는 UL 및 DL 전송에 서로 다른 local oscillator를 활용함으로써 duplexing 프로세스를 효과적으로 관리하고 효율적인 통신을 보장함</li>
    </ul>
  </li>
</ul>

<p class="note">UE의 최대 bandwidth를 40MHz로 늘리는 의견이 나왔지만, 대역폭을 늘리면 폼 펙터의 크기가 커지기 떄문에 기각됨.</p>

<ol>
  <li>Higher layer supported features</li>
</ol>

<ul>
  <li><strong>RedCap UE type</strong>
    <ul>
      <li>Rel-17에서 한가지의 RedCap UE 타입이 필수 UE capability와 RRC parameter들과 정의됨.</li>
    </ul>
  </li>
  <li><strong>Early indication</strong>
    <ul>
      <li>Initial access procedure에서 Msg1과 Msg3을 통한 early indication이 지원됨.</li>
    </ul>
  </li>
  <li><strong>DRX enhancement</strong>
    <ul>
      <li>DRC cycle이 확장되어 길어진 sleeping time과 energy saving을 달성함.</li>
      <li>정확한 signaling procedure들과 자세한 구현들은 3GPP RAN2에 정의되어 있음.</li>
    </ul>
  </li>
  <li><strong>RRM measurement relaxations</strong>
    <ul>
      <li>Rel-17 RRM measurement relaxation들은 RedCap UE의 requirement들을 맞추기 위해 추가 연구가 필요함.</li>
    </ul>
  </li>
</ul>

<h2 id="key-characteristics-and-analysis-for-rel-17-redcap-ue">Key Characteristics and Analysis for REL-17 RedCap UE</h2>

<h3 id="a-reduced-redcap-ue-bandwidth">A. Reduced RedCap Ue Bandwidth</h3>

<p>RedCap UE의 bandwidth capability는 complexity 감소를 위해 대폭 절감되었다.</p>

<p>일반 UE와 RedCap UE가 공존할 때, 초기 UL/DL BWP가 RedCap UE의 대역폭보다 넓은 경우에 RACH 접속 기회나 최적의 SSB가 RedCap UE의 대역폭을 벗어나는 경우가 발생한다. 이로 인해 RedCap UE는 정상적인 네트워크 접속에 실패할 수 있다.</p>

<p>Bandwidth 불일치로 인한 문제를 최소화하기 위해 여러 방법이 제안되고 연구되고 있다. 즉 RedCap UE가 제한된 대역폭 내에서도 효율적으로 작동할 수 있도록 하는 연구가 진행되고 있다.[3GPP TSG RAN1#108, R1-2202535, RAN1 agreements for Rel-17 NR
RedCap[R], Ericsson, Nov.2021]</p>

<ul>
  <li><strong>Method 1: Up to gNB implementation</strong>
    <ul>
      <li>초기에 회사들이 gNB의 resource configuration에 적절한 제약들을 걸어 bnadwidth의 불일치를 막는 방법을 제안함.</li>
      <li>필연적으로 RedCap UE와 일반 UE에게 performance loss를 가져옴.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/blog/RedCap/Figure1.png" alt="Figure1" /></p>

<ul>
  <li><strong>Method 2: Proper RF retuning for RedCap UE</strong>
    <ul>
      <li>RF retuning의 기본 아이디어는 frequency 포인트를 다른 frequency 포인트로 이동시키는 것임.
        <ul>
          <li>이동시키는 과정에서 약간의 delay가 발생함.</li>
          <li>저지연이 필요한 RedCap UE에서 적절한 RF retuning을 쓰는 것이 중요함</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>Method 3: Separate initial UL/DL BWPs for RedCap UE</strong>
    <ul>
      <li>가장 효과적인 방법은 initial UL/DL BWP와 RedCap UE의 BWP를 분리시키는 것임.</li>
      <li>SSB와 전체 CORESET#0을 별도의 초기 DL BWP에 포함시킬지 여부, TDD에서 초기 UL 및 DL BWP의 중심 주파수가 다른 경우를 지원할지 여부 등 몇 가지 논란이 존재하였음
        <ul>
          <li>Rel-17에서 specification impact와 system performance 사이의 균형을 고려하여 최종적으로 내려짐.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>TDD에서 UL과 DL의 BWP center frequeny는 동일하게 설정되어야 한다. Rel-17에서 TDD의 UL과 DL center frequency가 다르다는 직접적인 언급은 없지만 다르게 설정한다면 표준에 큰 영향을 미치고 구현 복잡도가 증가하기 때문에 center frequency가 같아야한다는 암묵적인 동의가 존재한다.</p>

<p><img src="/assets/img/blog/RedCap/Figure2.png" alt="Figure2" /></p>

<p>요약하면 RedCap UE의 flexibility를 위해 UL과 DL의 초기 BWP를 분리할 수 있지만, center frequency가 다른 경우 이를 해결하기 위해 적절한 retuning 절차를 사용해야 한다.</p>

<p>Rel-17에서 논의 끝에 <code class="language-plaintext highlighter-rouge">Method 3</code>이 UE bandwidth mismatch를 해결하기 위한 방법으로 선정되었다.</p>

<h3 id="b-collison-resolutions-in-half-duplex-mode">B. Collison Resolutions in Half-duplex Mode</h3>

<p>HD-FDD는 크게 두 가지 모드, Type A와 Type B로 나눌 수 있다. 두 모드의 차이점은 UL과 DL에서 같은 local oscillator를 사용하는지 여부이다.</p>

<ul>
  <li>HD-FDD Type A
    <ul>
      <li>UL과 DL이 서로 다른 local oscillator를 사용함</li>
      <li>UL과 DL의 switching이 빠름</li>
    </ul>
  </li>
  <li>HD-FDD Type B
    <ul>
      <li>UL과 DL이 같은 local oscillator를 사용함</li>
      <li>비용을 절감할 수 있지만 complexity 증가</li>
    </ul>
  </li>
</ul>

<p class="note">Rel-17 RedCap UE는 HD-FDD Type A를 지원하기로 합의함</p>

<p>HD-FDD RedCap UE는 신호 송수신이 동시에 불가능하기 때문에 UL 송신과 DL 수신에 충돌이 발생할 수 있다.</p>

<p>이를 해결하기 위해</p>
<ol>
  <li>gNB에 의핸 합리적인 scheduling 필요</li>
  <li>표준에 최소한의 영향을 주는 송신 prioritiy들 정의</li>
</ol>

<p>가 필수적이다.</p>

<p>충돌의 대표적인 예를 아래와 같이 정리할 수 있다.</p>

<ul>
  <li><em>Case 1: Collision due to direction switching</em>
    <ul>
      <li>UL과 DL이 HD-FDD Type A에서 direction switching을 하기 때문에 UL과 DL의 overlapping을 방지하기 위해 specific transition time이 필요하다.</li>
    </ul>
  </li>
  <li><em>Case 2: Dynamically scheduled DL reception conflicts with semi-statically configured UL transmission</em>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">partialCancellation</code>: UL symbol이 DL dynamically scheduled symbol과 overlap 되어 UL symbol의 전송이 취소될 수 있다.</li>
    </ul>
  </li>
  <li><em>Case 3: Semi-statically configured DL reception conflicts with dynamically scheduled UL transmission</em>
    <ul>
      <li>동적으로 스케쥴링된 UL 송신이 semi-statically 하게 구성된 DL 수신보다 더 높은 우선순위를 가진다.</li>
    </ul>
  </li>
  <li><em>Case 4: Configured SSB conflicts with UL transmission</em>
    <ul>
      <li>Initial access 시 SSB가 매우 중요하기 때문에, UL 송신 시 configured SSB를 전송하는 것에 높은 우선순위를 둔다.</li>
    </ul>
  </li>
  <li><em>Case 5: Valid RO(RACH Occasion) conflicts with DL reception</em>
    <ul>
      <li>Valid RACH Occasio에 RedCap은 두 가지 선택을 할 수 있음.
        <ol>
          <li>Downlink symbol을 계속 수신</li>
          <li>PRACH 자원을 사용해서 데이터를 전송</li>
        </ol>
      </li>
      <li>이는 각각의 장비나 상황에 따라 결정됨</li>
    </ul>
  </li>
</ul>

<h3 id="c-early-indication">C. Early Indication</h3>
<p>RedCap UE의 early indication은 normal UE와 공존할 때 resource allocation에서 유용함. RedCap UE가 initial access 시 early identified 되면 적절한 scheduling이 시스템 성능을 개선하기 위해 이뤄질 수 있음.</p>

<p>Early indication에 두가지 옵션이 존재함</p>

<ul>
  <li><strong>Early indication via Msg1</strong>
    <ul>
      <li>RedCap UE에 대한 초기 신호를 더 빨리 제공하기 위해, PRACH(Physical Random Access Channel) 자원을 별도로 설정하거나, PRACH preamble을 분할하는 방식을 적용할 수 있다.</li>
      <li>이 방법은 강한 scalability와 simplicity를 가지고 있지만 PRACH resource overhead와 PRACH user capacity를 감소시키는 단점을 가지고 있다.</li>
    </ul>
  </li>
  <li><strong>Early indication via Msg3</strong>
    <ul>
      <li>Msg1 기반 early indication의 supplement로 사용</li>
      <li>이 방법은 네트워크의 커버리지 회복, Msg4의 link adaptation, 필요한 경우 Msgㅇ의 resource scheduling 등에서 더 나은 성능을 달성할 수 있게 도와준다.</li>
      <li>Msg3에서 사용할 수 있는 여분의 비트 수는 매우 제한적이며 이를 사용하게 되면 네트워크와 터미널 장치의 complexity가 증가한다.
        <ul>
          <li>이를 해결하기 위해 3GPP에서는 LCID(Logical Channel Index)를 사용하여 Msg3 기반 early indication을 적용하기로 합의하였다.</li>
        </ul>
      </li>
    </ul>

    <h3 id="d-energy-saving">D. Energy Saving</h3>
  </li>
  <li>DRX enhancement
    <ul>
      <li><code class="language-plaintext highlighter-rouge">idle</code>과 <code class="language-plaintext highlighter-rouge">inactive</code> 상태에 있는 DRX cycle을 늘리는 것으로 고려중임.</li>
    </ul>
  </li>
  <li>RRM measurement relaxation
    <ul>
      <li>RRM measurement 주기 늘리기, 측정 지표의 수 줄이기, 새로운 측정 기준을 도입하기 등</li>
      <li>최소한의 RRM measurement를 사용하여 장치의 배터리 수명을 연장시킨다.</li>
    </ul>
  </li>
</ul>

<h2 id="analysis-and-solutions-for-coexistence-problems">Analysis and Solutions for Coexistence Problems</h2>

<p>서로 다른 UE capability 때문에 early indication과 BWP configuration에서 coexistence 문제들이 발생할 수 있다. Early indication에서 특정 RedCap UE를 구분하는 문제가 있다.</p>

<p>또한, Msg1과 Msg3을 이용한 합리적인 resource allocation이 추가적으로 논의되어야 한다.</p>

<p><img src="/assets/img/blog/RedCap/Figure3.png" alt="Figure3" /></p>

<p>일반 UE와 다양한 타입의 RedCap UE가 공존하는 상황에서 하나의 initial BWP로는 성능 저하가 발생할 수 있다. 이를 개선하기 위해 여러 개의 초기 BWP들을 지원하는 것이 필요하다.</p>

<ol>
  <li>Dedicated ROs
    <ul>
      <li>특정 UE나 서비스에 전용으로 할당된 Random Access 기회를 의미함</li>
      <li>특정한 요구사항이 있는 통신(ex. 긴급 통신, 특수 장비 사용 등)을 위해 사용</li>
      <li>Dedicated RO를 사용하면 해당 UE는 더 빠르고 확실한 네트워크 접속을 보장받을 수 있음</li>
    </ul>
  </li>
  <li>Shared ROs
    <ul>
      <li>여러 UE가 공유하는 Random Access 기회를 의미함</li>
      <li>ROs는 네트워크 자원을 여러 사용자가 공유하여 효율적으로 사용할 수 있게 한다.</li>
      <li>Shared ROs는 네트워크 트래픽이 많은 시간대에 여러 사용자가 접속을 시도할 때 사용된다.</li>
    </ul>
  </li>
</ol>

<h2 id="rel-18-redcap-ue-evolution">Rel-18 RedCap UE Evolution</h2>
<p>Rel-18 RedCap UE는 두개의 main 목표를 가지고 있다.</p>
<ol>
  <li>UE complexity와 비용 감소</li>
  <li>DRX 메커니즘 강화</li>
</ol>

<p>위와 같은 문제들은 Rel-17 RedCap, Rel-18 RedCap, Normal UE가 공존하는 상황을 바탕으로 연구가 된다.</p>

<h1 id="3-take-away">3. Take Away</h1>
<ul>
  <li>RedCap에 대한 지식</li>
  <li>RedCap UE에서 추가로 연구될만한 분야(conflicts in resource allocation)</li>
</ul>]]></content><author><name>Geon Kim</name><email>gun@khu.ac.kr</email></author><category term="paper" /><category term="tp" /><category term="stat" /><summary type="html"><![CDATA[**Authors**: Xiao Li, Xiaohang Xu, Chunlei Hu]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/RedCap/RedCap.png" /><media:content medium="image" url="http://localhost:4000/assets/img/blog/RedCap/RedCap.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Forecasting at Scale</title><link href="http://localhost:4000/blog/paper/2024-06-10-Forecasting-at-Scale-copy/" rel="alternate" type="text/html" title="Forecasting at Scale" /><published>2024-06-10T00:00:00+09:00</published><updated>2024-06-10T00:00:00+09:00</updated><id>http://localhost:4000/blog/paper/Forecasting-at-Scale%20copy</id><content type="html" xml:base="http://localhost:4000/blog/paper/2024-06-10-Forecasting-at-Scale-copy/"><![CDATA[<p class="note" title="Keywords">Time Series, Statistical Practice, Nonlinear Regression</p>

<ul id="markdown-toc">
  <li><a href="#1-why-this-paper" id="markdown-toc-1-why-this-paper">1. Why this paper</a></li>
  <li><a href="#2-summary-of-paper" id="markdown-toc-2-summary-of-paper">2. Summary of paper</a>    <ul>
      <li><a href="#21-introduction" id="markdown-toc-21-introduction">2.1 Introduction</a></li>
      <li><a href="#22-features-of-business-time-seriers" id="markdown-toc-22-features-of-business-time-seriers">2.2 Features of Business Time Seriers</a></li>
      <li><a href="#23-the-prophet-forecasting-model" id="markdown-toc-23-the-prophet-forecasting-model">2.3 The Prophet Forecasting Model</a>        <ul>
          <li><a href="#231-the-trend-model" id="markdown-toc-231-the-trend-model">2.3.1 The Trend Model</a>            <ul>
              <li><a href="#2311-nonlinear-saturating-growth" id="markdown-toc-2311-nonlinear-saturating-growth">2.3.1.1 Nonlinear, Saturating Growth</a></li>
              <li><a href="#2312-linear-trend-with-changepoints" id="markdown-toc-2312-linear-trend-with-changepoints">2.3.1.2 Linear Trend with Changepoints</a></li>
              <li><a href="#2313-automatic-changepoint-selection" id="markdown-toc-2313-automatic-changepoint-selection">2.3.1.3 Automatic Changepoint Selection</a></li>
              <li><a href="#2314-trend-forecast-uncertainty" id="markdown-toc-2314-trend-forecast-uncertainty">2.3.1.4 Trend Forecast Uncertainty</a></li>
            </ul>
          </li>
          <li><a href="#232-seasonality" id="markdown-toc-232-seasonality">2.3.2 Seasonality</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#3-take-away" id="markdown-toc-3-take-away">3. Take away</a></li>
</ul>

<h1 id="1-why-this-paper">1. Why this paper</h1>
<ul>
  <li>통계 기반 시계열 예측 알고리즘 조사</li>
  <li>SKT AI Fellowship 비교 알고리즘 개발에 필요</li>
</ul>

<h1 id="2-summary-of-paper">2. Summary of paper</h1>

<h2 id="21-introduction">2.1 Introduction</h2>

<ul>
  <li>비즈니스 단계에서 높은 수준의 시계열 예측이 어려운 이유
    <ol>
      <li>완전 자동화된 예측 기술들은 튜닝하기 어렵고, heuristic에 비해 유연하지 않음</li>
      <li>조직 내 데이터 전문가들이 시계열 예측에 대해 익숙하지 않을 수 있음</li>
    </ol>
  </li>
</ul>

<p class="note">규모에 상관없는 forecasting을 만들기 위한 유용한 가이드라인들을 제공하는 것이 목적임</p>

<p>본 논문에서는 큰 스케일의 시계열 트래픽을 예측하는 것이 상대적으로 간단하다고 한다. 병렬화가 매우 용이하며 예측 결과를 관계형 데이터베이스에 저장하는 것도 어렵지 않기 떄문이다. 진짜 큰 어려움은 <strong>예측 결과의 신뢰성</strong>이다.</p>

<p><img src="/assets/img/blog/prophet/prophet1.png" alt="Figure.1" /></p>

<ol>
  <li>각 parameter가 쉽게 이해될 수 있도록 유연한 방법으로 시계열을 모델링</li>
  <li>모델과 기준 모델에 대해 다양한 과거 데이터에 대한 예측을 생성 후, 성능 평가</li>
  <li>성능이 좋지 않을 경우, 우선순위를 정해 문제를 전문가에게 알림</li>
  <li>분석가가 이를 검토하고 피드백을 바탕으로 모델을 조정</li>
</ol>

<h2 id="22-features-of-business-time-seriers">2.2 Features of Business Time Seriers</h2>

<p><img src="/assets/img/blog/prophet/prophet2.png" alt="Figure.2" /></p>

<p class="note">위의 그림은 <strong>R</strong>의 <strong>forecasting</strong> 패키지를 이용해 다양한 알고리즘으로 예측을 수행한 것이다.</p>

<p>전체 시간 중 세개의 구역에서 예측을 수행하였으며, 각각의 예측은 시작 지점 전까지의 시계열 데이터만을 이용하여 해당 날짜에 예측을 수행하는 시뮬레이션을 한 것이다. 예측에는 아래의 알고리즘들이 사용되었다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">auto.arima</code>
    <ul>
      <li>ARIMA 모델 여러개 중 가장 성능이 좋은 모델을 고름</li>
      <li>Large trend error에 취약</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">ets</code>
    <ul>
      <li>여러 개의 exponential 함moothing model 중 가장 은능이 좋은 모델을 고름</li>
      <li>주간 trend 데이터의 계절성은 잘 포착하지만, 장기간 trend 계절성은 잘 포착하지 못함</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">snaive</code>
    <ul>
      <li>계절성을 가지는 데이터를 예측하는 데 사용되며, 매주 반복되는 패턴을 가진 데이터에 적합함</li>
      <li>주간 trend 데이터의 계절성은 잘 포착하지만, 장기간 trend 계절성은 잘 포착하지 못함</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">tbats</code>
    <ul>
      <li>주간 혹은 연간 계절성을 가지는 데이터에 적합함</li>
    </ul>
  </li>
</ul>

<p class="note">예측이 잘못되었을 때 모델의 parameter들을 튜닝해야 하는데 이 과정에서 시계열 모델에 대한 깊은 이해가 필요함</p>

<h2 id="23-the-prophet-forecasting-model">2.3 The Prophet Forecasting Model</h2>

<p>Harvey &amp; Peters가 제안한 방법을 활용하여 시계열 데이터를 세가지 주요 컴포넌트로 분류하였다: trend, seasonality, and holidays. 아래의 식과 같이 나타낼 수 있다.</p>

\[y(t) = g(t) + s(t) + h(t) + \epsilon_{t}\]

<ul>
  <li>\(g(t)\) : 시계열 데이터에서 비주기적인 변화를 모델링하는 trend 함수</li>
  <li>\(s(t)\) : 주기적인 변화(e.g., weekly 혹은 yearly 계절성)를 나타냄</li>
  <li>\(h(t)\) : 하루 혹은 그 이상으로 불규칙적으로 스케쥴링 된 날들을 모델링하는 holiday 함수</li>
  <li>\(\epsilon_{t}\) : 모델에 캡쳐되지 않는 독특한 변화들, 후에 normally 분포되었다고 가정할 예정</li>
</ul>

<p>이러한 구조는 Hastie &amp; Tibshiran이 제안한 Generalized Additive Model(GAM)과 유사하다</p>

<blockquote>
  <p>Non-linear smoothers가 regressor에 적용된 regression model의 한 종류</p>
</blockquote>

<p>여기서는 시간만을 regressor로 사용하지만, 시간의 여러 선형 및 비선형 함수들을 구성 요소로 사용할 수 있다.</p>

<p>GAM 공식은 분해하기 쉽고 필수적으로 새로운 컴포넌트들을 포함한다는 장점이 있다. 또한 매우 빠르게 환경에 적응한다. 따라서 사용자들은 모델 parameter들을 이에 맞춰 변화시킬 수 있다.</p>

<p>본 논문의 저자들은 예측 문제를 <strong>curve-fitting exercise</strong>로 정의하였다. 이는 데이터의 시간 의존 구조를 고려하는 시계열 모델과 본질적으로 다르다.</p>

<p>ARIMA와 같은 생성 모델을 이용하면 얻을 수 있는 inferential 장점들을 포기해야 하지만 아래와 같은 practical한 장점들을 얻을 수 있다.</p>

<ul>
  <li>Flexibility: 다양한 기간의 계절성을 쉽게 반영할 수 있으며, 분석가가 trend에 대한 다양한 가정을 할 수 있게 한다.</li>
  <li>ARIMA와 달리 측정값이 규칙적으로 분포될 필요가 없으며, 결측값을 보간할 필요 없다.</li>
  <li>Fitting 속도가 빠르다.</li>
  <li>해석하기 쉬운 파라미터들을 가지고 있어 분석가가 다루기 용이하다.</li>
</ul>

<h3 id="231-the-trend-model">2.3.1 The Trend Model</h3>

<p>본 논문에서는 두가지 trend 모델을 설명하고 있는데,</p>

<ol>
  <li>Nonlinear, Saturating Growth</li>
  <li>Linear Trend with Changepoints</li>
</ol>

<p>가 해당한다.</p>

<h4 id="2311-nonlinear-saturating-growth">2.3.1.1 Nonlinear, Saturating Growth</h4>

<p>Growth 예측에 있어 데이터 생성 프로세스의 중요 구성요소는 population이 어떻게 증가하였고 증가할 것인지를 모델링하는 것이다. 주로 logistic growth 모델을 사용하여 이러한 종류의 growth를 모델링한다.</p>

<p>\(g(t) = \frac{C}{1 + \exp(-l(t - m))}\)</p>
<ul>
  <li>\(C\): carrying capacity</li>
  <li>\(k\): growth rate</li>
  <li>\(m\): offset 파라미터</li>
</ul>

<p>하지만 Facebook이 포착해내지 못한 두가지 요소가 있다.</p>
<ol>
  <li>Carrying capacity는 일정하지 않다.
    <ul>
      <li>해결책: \(C \rightarrow C(t)\)</li>
    </ul>
  </li>
  <li>Growth rate도 일정하지 않다.
    <ul>
      <li>해결책: \(k\)를 대체하는 많은 products</li>
    </ul>
  </li>
</ol>

<ul>
  <li>Growth 모델 안에 있는 trend changes를 포함하기 위해 changepoints를 정의하였다.
    <ol>
      <li>시간 \(s_j\) 안에 \(S\)개의 change point</li>
      <li>Rate adjustment 벡터: \(\delta \in \mathbb{R}^{S}\)</li>
    </ol>
    <ul>
      <li>Adjustment의 식:  \(k+\sum_{j:t&gt;s_j}\delta_{j}\)</li>
      <li>벡터 \(a(t) \in {0, 1}^{S}\)를 이용해 식을 명확하게 나타내면</li>
    </ul>
  </li>
</ul>

\[a_j(t) = 
\begin{cases} 
1, &amp; \text{if } t \geq s_j, \\ 
0, &amp; \text{otherwise}.
\end{cases}\]

<p>시간 \(t\)의 rate는 \(k+a(t)^{\intercal}\lambda\)가 된다. Rate \(k\)가 결정되었을 때, offset 파라미터 \(m\)도 각 세그먼트들의 endpoint들을 잇기 위해 조정된다.</p>

<ul>
  <li>Changeoint \(j\)에서의 correct adjustment는 아래와 같이 정의된다.</li>
</ul>

\[\gamma_j = \left(s_j - m - \sum_{l&lt;j} \gamma_l \right) \left(1 - \frac{k + \sum_{l&lt;j} \delta_l}{k + \sum_{l \leq j} \delta_l}\right)\]

<ul>
  <li>각 부분의 logistic growth 모델도 다음과 같다.</li>
</ul>

\[g(t) = \frac{C(t)}{1 + \exp \left( -(k + a(t)^{\top}\delta) \left( t - (m + a(t)^{\top}\gamma) \right) \right)}\]

<p>본 논문의 모델에서 중요한 파라미터의 집합은 \(C(t)\)이다. 데이터에 인사이트가 깊은 분석가들은 데이터 특성에 맞춰 \(C(t)\)를 설정하곤 한다.</p>

<h4 id="2312-linear-trend-with-changepoints">2.3.1.2 Linear Trend with Changepoints</h4>

<p>Saturating growth를 가지고 있지 않은 forecasting 문제들, 즉 constant rate of growth는 간단하고 유용한 모델을 제공한다.</p>

\[g(t) = (k + a(t)^{\intercal}\lambda)t + (m + a(t)^{\intercal}\gamma)\]

<p>이 때 \(\gamma_{j}\)는 function을 연속적으로 만들기 위해 아래와 같이 설정된다.</p>

\[\gamma_{j} = -s_{j}\lambda_{j}\]

<h4 id="2313-automatic-changepoint-selection">2.3.1.3 Automatic Changepoint Selection</h4>

<p>분석가들은 프로덕트가 시작된 날짜, 다른 growth-altering 사건들에 대한 정보를 이용해 changepoint \(s_j\)를 결정한다. \(s_j\)의 automatic selection은 \(\delta\)에 sparse prior을 둠으로써 자연스럽게 이루어진다.</p>

<p>다수의 changepoint들을 특정할 때 \(\delta_{j} \sim Laplace(0, \tau)\)를 사용한다.</p>
<ul>
  <li>\(\tau\): 직접적으로 모델의 flexibility를 조절</li>
</ul>

<p>Adjustment \(\lambda\)의 spare prior는 primary growth rate \(k\)에 영향을 미치지 않기 때문에, \(\tau\)가 0이 되면 모델은 단순한 logistic 또는 linear growth 모델로 변환된다.</p>

<h4 id="2314-trend-forecast-uncertainty">2.3.1.4 Trend Forecast Uncertainty</h4>

<p>예측의 불확실성을 생성 모델을 이용해서 측정한다. Trend를 위한 generative 모델은 \(T\)개의 데이터 포인트로 구성된 과거 기록에서 \(S\)개의 변화점이 있으며, 각 변화점은 \(\lambda_{j} \sim Laplace(0, \tau)\)의 분포를 가진다.</p>

<p>미래의 rate 변화를 과거의 데이터에서 \(\tau\)를 바꿔 에뮬레이션한 값으로 대체하며 시뮬레이션을 진행한다. Bayesian 프레임워크에서는 \(\tau\)의 hierarchical prior을 이용해 posterior를 구해 진행할 수 있다. 다른 방법으로는 rate scale 파라미터: \(\lambda = \frac{1}{S} \sum_{j=1}^{S} \|\delta_j\|\) 의 maximum likelihood estimate를 사용할 수 있다.</p>

<p>미래의 changepoint들도 과거 chagepoint들의 평균 frequency에 맞춰 랜덤하게 샘플된다.</p>

\[\forall j &gt; T,
\begin{cases}
\delta_j = 0 &amp; \text{w.p.} \ \frac{T - S}{T}, \\
\delta_j \sim \text{Laplace}(0, \lambda) &amp; \text{w.p.} \ \frac{S}{T}.
\end{cases}\]

<p>미래의 trend가 과거의 trend를 따를것이라는 가정은 강력한 가정이기 때문에 예측에 실패한 구간을 만들 수도 있다.</p>

<p>\(\tau\)가 증가할수록 모델의 과거 데이터를 더 유연하게 맞출 수 있어 training error가 줄어든다. 그러나 이 flexibility로 인해 예측에 실패한 구간이 넓어질 것이다.</p>

<h3 id="232-seasonality">2.3.2 Seasonality</h3>

<p>비즈니스 시계열 데이터는 사람들의 행동 패턴에 따라 계절성을 가지게 된다. 이 계절성을 예측하기 위해 정확하게 계절성 데이터를 모델링해야 한다. 본 논문에서는 periodic effects에 flexible 모델을 제공하기 위해 <code class="language-plaintext highlighter-rouge">Fourier series</code>를 사용한다.</p>

<p>Arbitrary smooth seasonal effects를 다음과 같이 모델링할 수 있다.</p>

\[s(t) = \sum_{n=1}^{N} \left( a_n \cos \left( \frac{2 \pi n t}{P} \right) + b_n \sin \left( \frac{2 \pi n t}{P} \right) \right)\]

<ul>
  <li>Fourier 계수 추정
    <ul>
      <li>Seasonal 패턴을 정의하기 위해 2N개의 parameter를 추정해야 한다.</li>
      <li>이를 위해 각 시간 \(t\)에 대한 행렬 \(X(t)\)를 구성한다.</li>
    </ul>
  </li>
  <li>계절성 계산
    <ul>
      <li>
\[s(t) = X(t)\beta\]
        <ul>
          <li>
\[\beta \sim Normal(0, \sigma^2)\]
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="3-take-away">3. Take away</h1>]]></content><author><name>Geon Kim</name><email>gun@khu.ac.kr</email></author><category term="paper" /><category term="tp" /><category term="stat" /><summary type="html"><![CDATA[**Authors**: Attai Ibrahim Abubakar, Hichael S. Mollel, Metin Ozturk, Sajjad Hussain, and Muhammad Ali Imran]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/prophet/prophet_logo.webp" /><media:content medium="image" url="http://localhost:4000/assets/img/blog/prophet/prophet_logo.webp" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">A Lightweight Cell Switching and Traffic Offloading Scheme for Energy Optimization in Ultra-Dense Heterogeneous Netweorks</title><link href="http://localhost:4000/blog/paper/2024-06-04-lightweight-cell-switching/" rel="alternate" type="text/html" title="A Lightweight Cell Switching and Traffic Offloading Scheme for Energy Optimization in Ultra-Dense Heterogeneous Netweorks" /><published>2024-06-04T00:00:00+09:00</published><updated>2024-06-04T00:00:00+09:00</updated><id>http://localhost:4000/blog/paper/lightweight-cell-switching</id><content type="html" xml:base="http://localhost:4000/blog/paper/2024-06-04-lightweight-cell-switching/"><![CDATA[<p class="note" title="Keywords">Cell-switching, HetNet, Traffic-offloading</p>

<ul id="markdown-toc">
  <li><a href="#1-why-this-paper" id="markdown-toc-1-why-this-paper">1. Why this paper</a></li>
  <li><a href="#2-summary-of-paper" id="markdown-toc-2-summary-of-paper">2. Summary of paper</a>    <ul>
      <li><a href="#21-introduction" id="markdown-toc-21-introduction">2.1 Introduction</a></li>
      <li><a href="#22-contributions" id="markdown-toc-22-contributions">2.2 Contributions</a></li>
      <li><a href="#23-system-model" id="markdown-toc-23-system-model">2.3 System Model</a>        <ul>
          <li><a href="#23a-network-model" id="markdown-toc-23a-network-model">2.3.A Network model</a></li>
          <li><a href="#23b-udhn의-소모-전력" id="markdown-toc-23b-udhn의-소모-전력">2.3.B UDHN의 소모 전력</a></li>
        </ul>
      </li>
      <li><a href="#24-problem-formulation" id="markdown-toc-24-problem-formulation">2.4 Problem Formulation</a></li>
      <li><a href="#25-proposed-cell-switching-scheme" id="markdown-toc-25-proposed-cell-switching-scheme">2.5 Proposed Cell Switching Scheme</a>        <ul>
          <li><a href="#25a-cell-clustering" id="markdown-toc-25a-cell-clustering">2.5.A Cell clustering</a></li>
          <li><a href="#25b-multi-level-clustering-based-cell-switching-scheme" id="markdown-toc-25b-multi-level-clustering-based-cell-switching-scheme">2.5.B Multi-level clustering based cell switching scheme</a></li>
          <li><a href="#25c-threshold-based-hybrid-cell-switching-scheme" id="markdown-toc-25c-threshold-based-hybrid-cell-switching-scheme">2.5.C Threshold-based Hybrid Cell Switching Scheme</a></li>
        </ul>
      </li>
      <li><a href="#26-performance-evaluation" id="markdown-toc-26-performance-evaluation">2.6 Performance Evaluation</a>        <ul>
          <li><a href="#26a-traffic-data-and-simulation-parameters" id="markdown-toc-26a-traffic-data-and-simulation-parameters">2.6.A Traffic data and simulation parameters</a></li>
          <li><a href="#26b-performance-metrics" id="markdown-toc-26b-performance-metrics">2.6.B Performance metrics</a></li>
          <li><a href="#26c-benchmarks" id="markdown-toc-26c-benchmarks">2.6.C Benchmarks</a></li>
          <li><a href="#26d-results-and-discussions" id="markdown-toc-26d-results-and-discussions">2.6.D Results and Discussions</a></li>
        </ul>
      </li>
      <li><a href="#27-conclusion" id="markdown-toc-27-conclusion">2.7 Conclusion</a></li>
    </ul>
  </li>
  <li><a href="#3-take-away" id="markdown-toc-3-take-away">3. Take Away</a></li>
</ul>

<h1 id="1-why-this-paper">1. Why this paper</h1>

<ul>
  <li>Cell switching에 쓰이는 가벼운 알고리즘 구상에 필요</li>
  <li>Milan 데이터셋을 이용한 논문</li>
</ul>

<h1 id="2-summary-of-paper">2. Summary of paper</h1>

<h2 id="21-introduction">2.1 Introduction</h2>

<p>UDN 환경에서 아래와 같은 다양한 방법들이 전력 소모 최적화를 위해 사용되어 왔다.</p>

<ul>
  <li>Antenna muting</li>
  <li>Cell zooming</li>
  <li>Power control</li>
  <li>Sectorization</li>
  <li>Dynamic cell switching operations</li>
</ul>

<p>이 중 가장 전력을 절감할 수 있고 보편적으로 연구되고 있는 분야는 dynamic cell switching이다. 또한, cell switching은 기존 아키텍쳐에 최소한의 변화를 통해 실현시킬 수 있기 때문에 구현이 쉽다는 장점이 있다.</p>

<p>Cell switching을 위해 다양한 머신러닝 기법들이 제안되고 있다.</p>

<ol>
  <li>지도학습(e.g., artificial neural networks (ANN))</li>
  <li>비지도학습(e.g., k-means)</li>
  <li>강화학습(e.g., deep and double-deep Q-learning)</li>
</ol>

<p><strong>머신러닝 기반 알고리즘</strong>은 뛰어난 generalization 능력을 가지고 있고 급변하는 네트워크 환경에 적응할 수 있지만, training process가 컴퓨팅 자원을 많이 소모하여 실시간 네트워크에 사용하기 힘든 단점을 가지고 있다.</p>

<p><strong>휴리스틱 기반 알고리즘</strong>은 구현하기 쉽지만 generalization 능력이 부족하고, 급변하는 네트워크 환경에 적응할 수 없다는 단점을 가지고 있다.</p>

<p>본 논문에서는 optimal cell switching 기법으로 <code class="language-plaintext highlighter-rouge">exhaustive search algorithm (ES)</code>를 제안한다. 완전탐색은 사용 가능한 모든 SBS 조합을 탐색하기 때문에 최적의 조합을 찾아낼 수 있다. 하지만 이 방법은 SBS의 수가 늘어나면 컴퓨팅 자원 소모가 급격하게 늘어난다는 치명적인 단점을 가지고 있다.</p>

<p><code class="language-plaintext highlighter-rouge">ES</code>를 보완하기 위해 대안 방법으로 생각해낸 것이 clustering을 이용해 탐색 공간을 줄이고 완전탐색을 하여 소모 시간을 줄이는 것이다. 본 논문에서는 이를 기반으로 만든 <code class="language-plaintext highlighter-rouge">Threshold-based Hybrid cEll swItching Scheme(THESIS)</code> 알고리즘을 제안한다.</p>

<h2 id="22-contributions">2.2 Contributions</h2>

<ol>
  <li><strong>THESIS</strong>, k-means + ES 알고리즘을 통해 UDHN에서의 에너지 최적화를 실현시킴. 제안 알고리즘은 computationally 효율적이고 optimal 솔루션에 가까운 결과를 냄. 또한, 대규모 네트워크 환경에도 적용 가능함.</li>
  <li>비교 알고리즘은 단순히 k-means만 사용</li>
  <li>\(CO_{2}\) 절감량도 측정</li>
  <li>제안 알고리즘과 비교 알고리즘의 엄밀한 비교를 통한 computational 효율성 검증</li>
  <li>실제 네트워크 데이터를 이용하여 알고리즘의 scalability와 성능을 검증</li>
</ol>

<h2 id="23-system-model">2.3 System Model</h2>

<h3 id="23a-network-model">2.3.A Network model</h3>

<p>여러 개의 macro cells(MCs)로 이루어진 UDHN(Ultra Dense Heterogeneous Netweork) 환경을 고려한다. 각각의 MBS는 각기 다른 capacity와 power consumption을 가지고 있는 SBS들을 포함하고 있다.</p>

<p>UDHN은 CDSA(Control and Data Separated Architecture)를 채택한다.</p>

<ul>
  <li>MBS: 제어 BS를 담당하며 SBS들을 낮은 data rate로 커버리지 내에서 서비스</li>
  <li>SBS: 데이터 BS를 담당하며 높은 데이터 트래픽이 필요한 서비스 담당</li>
</ul>

<p><strong>Vertical traffic offloading</strong>: SBS가 traffic load가 없거나 적을 때, MBS로 traffic을 offloading</p>

<p>본 논문에서 정의하는 <code class="language-plaintext highlighter-rouge">QoS</code>: cell switching이 일어난 후 서비스 가능한 총 트래픽 양</p>

<p><img src="/assets/img/blog/lightweight-cs/figure.1.png" alt="Figure.1" /></p>

<h3 id="23b-udhn의-소모-전력">2.3.B UDHN의 소모 전력</h3>

<p>BS의 power 소비는 다음과 같다.</p>

\[P_{BS}(\lambda, t) = P_{o} + \lambda_{t}\eta P_{tx}\]

<ul>
  <li>\(P_{o}\): constant circuit power 소모</li>
  <li>\(\lambda_{t}\): 순간적인 traffic 로드</li>
  <li>\(\eta\): 로드와 관련있는 power 소모 컴포넌트</li>
  <li>\(P_{tx}\): BS의 송신 전력</li>
</ul>

<p>이 때 \(P_{o}, \eta, P_{tx}\)는 <strong>SBS의 종류</strong>에 따라 다르다.</p>

<p>UDHN의 총 소모 전력 \(P_u\)는 다음과 같다.</p>

\[P_{u}(\lambda, t) = \sum_{i} \sum_{j} P_{BS_{i,j}}(\lambda, t)\]

<ul>
  <li>\(P_{BS_{i,j}}\): \(i\)번째 MC(Macro Cell)에 속해있는 \(j\)번째 BS의 소모 전력</li>
  <li>\(P_{BS_{i,1}}\): \(i\)번째 MC에 속해있는 MBS의 소모 전력</li>
</ul>

<h2 id="24-problem-formulation">2.4 Problem Formulation</h2>
<p>\(T\)는 \(L\)의 길이를 가지는 duration으로 나뉜다. 이 때 \(u=[1,2,...,K]\)와 같이 \(T\) 안에 있는 \(L\) 길이의 블록 순서를 나타낼 수 있다. \(K\)는 \(T\)안에 있는 블록의 수이다(\(K=T/L\)).</p>

<p class="note">UDHN이 SBS가 낮은 트래픽 load를 가질 때 전원을 끄는 시나리오를 고려한다.</p>

<p>본 논문의 목적은 각 time slot에서 최소한의 전력 소모를 실현시킬 수 있는 최적의 switching strategy를 결정하는 것이다.</p>

\[P_u(\lambda, \Gamma_{i,j}) = \sum_{u} \sum_{i} \sum_{j} [\Gamma_{i,j}P_{BS_{i,j}}(\lambda,t) + (1-\Gamma_{i,j})P^{s}_{BS_{i,j}}]\]

<ul>
  <li>\(P^{s}_{BS_{i,j}}\): BS가 sleep mode일 때 소모 전력</li>
  <li>\(\Gamma_{i,j}\): t일 때, \((i,j)^{th}\) BS의 off/on 상태 (On일 때 1, Off일 때 0)</li>
</ul>

<p>따라서 power optimization objective function은 다음과 같이 작성할 수 있다.</p>

\[\begin{align*}
\max_{\Gamma_{i,j}}\quad &amp; P_u(\lambda, \Gamma_{i,j}), \tag{5} \\
\text{s.t}\quad &amp; z = \lambda_{i,1} + \sum_{j=2}^m \lambda_{i,j} \Gamma_{i,j}, \tag{6} \\
&amp; \hat{\lambda}_{i,1} \leq \lambda_{i,1}^m, \tag{7} \\
&amp; \Gamma_{i,j} \in \{0, 1\}. \tag{8}
\end{align*}\]

<ul>
  <li>Constraint (6): UDHN에 의해 지원되는 traffic demand는 cell switching과 traffic offloading 이전/이후 동일
    <ul>
      <li>\(z:\) Cell switching 이전 UDHN에 의해 지원되는 전체 traffic demand</li>
    </ul>
  </li>
  <li>Constraint (7): SBS에 의해 offloading 되는 traffic 총량이 MBS의 maximum traffic demand를 넘을 수 없다.
    <ul>
      <li>\(\hat{\lambda}_{i,1}\): Traffic offloading 이후 MBS의 traffic load</li>
      <li>\(\lambda^{m}_{i,1}\): MBS가 최대로 수용할 수 있는 traffic demand</li>
    </ul>
  </li>
  <li>Constraint (8): SBS의 상태는 on/off 둘 중 하나여야 함</li>
</ul>

<h2 id="25-proposed-cell-switching-scheme">2.5 Proposed Cell Switching Scheme</h2>

<p>최적 알고리즘으로 소개된 ES는 네트워크 규모가 커지면 계산 자원 요구량이 커지기 때문에 적합하지 않다. 이를 해결하기 위해 본 논문에서는 THESIS(k-means clustering + ES) 알고리즘을 제안한다.</p>

<h3 id="25a-cell-clustering">2.5.A Cell clustering</h3>

<p><strong>Selection of optimal number of clusters (elbow method)</strong></p>

<p>클러스터링에서 가장 중요한 것 중 하나는 데이터셋을 나눌 클러스터의 수를 결정하는 것이다.</p>

<p><code class="language-plaintext highlighter-rouge">elbow method</code>를 사용하여 최적의 클러스터 수를 결정할 수 있다.  <code class="language-plaintext highlighter-rouge">elbow method</code>에서 최적의 클러스터 수는 SSE(Sum of the Squares Errors)의 합으로 결정된다.</p>

\[SSE = \sum^{N}_{k=1}\sum(X-c_{k})^2\]

<ul>
  <li>\(k\): 클러스터의 수</li>
  <li>\(X\): 클러스터 안에 있는 data 포인트</li>
  <li>\(c_k\): 특정 클러스터의 평균값(중앙값)</li>
</ul>

<p class="note">SSE 곡선이 평탄화되기 전, elbow 모양을 보일 때 k값을 사용한다</p>

<h3 id="25b-multi-level-clustering-based-cell-switching-scheme">2.5.B Multi-level clustering based cell switching scheme</h3>

<p>MLC(Multi-level clustering) 알고리즘은 MBS의 커버리지 내에서 clustering과 light traffic load 된 SBS들을 MBS로 offload 하는 과정을 반복하여 최적의 클러스터 구성을 찾아낸다.</p>

<p><img src="/assets/img/blog/lightweight-cs/figure.2.png" alt="figure.2" /></p>

<p>알고리즘의 단계를 정리하면 다음과 같다.</p>

<ol>
  <li><strong>Elbow 방법을 사용하여 최적의 클러스터 수 결정</strong>: 데이터 포인트들을 클러스터링 하여 각 클러스터의 변동성이 최소가 되는 클러스터의 수를 찾는다.</li>
  <li><strong>k-평균 알고리즘을 적용하여 SBS 클러스터링</strong>: 최적의 클러스터 수를 기반으로 각 SBS의 트래픽 부하에 따라 첫 번째 레벨 클러스터링을 수행한다.</li>
  <li><strong>클러스터별 총 트래픽 부하 계산 및 비교</strong>: 각 클러스터의 트래픽 부하를 계산하고 이를 MBS에서 사용 가능한 무선 자원과 비교하여 off 할 수 있는 클러스터 수를 결정한다.</li>
  <li><strong>선택된 클러스터의 트래픽을 MBS로 오프로딩 후 네트워크의 전력 소비 계산</strong>: 선택된 클러스터의 트래픽을 MBS로 오프로딩하고, 그 결과로 네트워크의 전력 소비를 계산한다.</li>
  <li><strong>클러스터 추가 분할</strong>: 남은 클러스터 중 MBS가 처리할 수 있는 최대 트래픽 수요를 초과하는 클러스터는 더 작은 클러스터로 추가 분할하여 이전 단계들을 반복한다. 이 과정은 하나의 SBS만이 남을 때 까지 또는 더 이상 처리할 SBS가 없을 때까지 반복한다.</li>
  <li><strong>최종적인 전력 소비 계산 및 순위 매기기</strong>: 모든 클러스터링과 트래픽 오프로딩 작업 후 UDHN의 전력 소비를 계산하고, 얻은 전력 소비 값들을 오름차순으로 순위를 매겨 가장 낮은 전력 소비를 보이는 구성을 최적의 클러스터로 선택한다</li>
</ol>

<h3 id="25c-threshold-based-hybrid-cell-switching-scheme">2.5.C Threshold-based Hybrid Cell Switching Scheme</h3>

<p>앞에서 설명한 MLC 알고리즘이 대규모 네트워크에 적용할 수 있더라도 ES 알고리즘에 비해 sub-optimal 한 결과를 내게 된다. 어떠한 sub-optimal 알고리즘도 결국 ES 알고리즘과 근사한 결과를 낼 수 밖에 없다는 점을 기억하자.</p>

<p>이를 보완하고자 본 논문에서는 THESIS 알고리즘을 제안한다.
<img src="/assets/img/blog/lightweight-cs/figure.3.png" alt="Figure.3" /></p>

<p>MLC 방법과 같이 최적의 클러스터 수를 결정하는데 elbow 방법이 사용된다. 그 다음 k-means 알고리즘을 사용하여 SBS의 트래픽 로드를 기반으로 한 첫번째 단계의 클러스터링이 수행된다. 그 후, threshold value(\(B_{th}\))보다 작은 SBS 수를 가지는 클러스터가 결정된다. 그 클러스터는 ES 알고리즘을 이용해 전원을 꺼야 할 SBS를 결정하고 네트워크의 소모 전력이 계산된다.</p>

<p>\(B_{th}\)보다 큰 수의 SBS를 가지는 클러스터는 다시 한번 k-means 알고리즘을 사용해 재 클러스터링하고 ES를 적용하여 꺼야 할 SBS 수를 결정하고 네트워크의 전력 소비를 계산한다. 마지막으로, 다양한 SBS 세트를 꺼서 얻은 UDHN의 전력 소비를 기준으로 순위를 매긴다. 가장 작은 전력 소비를 보이는 SBS 세트를 최적의 꺼야 할 SBS 세트로 선택한다.</p>

<p>MLC와 다르게 THESIS 알고리즘은 클러스터 내에서 전원을 꺼야할 SBS를 고른다. 이를 통해 THESIS는 SBS들의 타입들(capacity and power consumption profile)을 구분할 수 있다.</p>

<h2 id="26-performance-evaluation">2.6 Performance Evaluation</h2>
<p>본 논문에서는 하나의 Macro cell 만을 가지고 시뮬레이션을 진행하였으며, 이 결과의 scalability가 증명되었기 때문에 상관없다고 언급한다. 시뮬레이션에서 사용한 파라미터는 아래의 그림과 같다.</p>

<p><img src="/assets/img/blog/lightweight-cs/figure.4.png" alt="Figure.4" /></p>

<h3 id="26a-traffic-data-and-simulation-parameters">2.6.A Traffic data and simulation parameters</h3>
<p>UDHN의 전체 전력을 계산하기 위해서는 MBS와 SBS들의 traffic load가 필요하다.</p>

<p>Milan 데이터셋의 inter activity level을 BS의 traffic load로 고려하였다. 임의로 선택한 두 개의 그리드를 결합하여 MBS의 트래픽 부하로 나타냈고, SBS의 경우 단일 그리드로 고려하였다. 그 후, 트래픽 부하는 UDHN의 각 SBS의 무선 자원 양에 따라 정규화 되었다.</p>

<h3 id="26b-performance-metrics">2.6.B Performance metrics</h3>
<ul>
  <li><strong>Power Consumpiton</strong>: UDHN 시뮬레이션 도중 소비한 instantaneous 소모 전력</li>
  <li><strong>Energy Saved</strong>: 24시간 동안 절감된 에너지 양을 측정</li>
  <li><strong>Carbon Emission</strong>: \(\mathcal{E}_{CO_2} = \zeta\sum_{t=1}^{T}E_{u,t}\) (\(\zeta\): \(CO_2\) conversion factor)</li>
  <li><strong>Average Network Throughput</strong>: Active BS들에 의해 서비스될 수 있는 총 네트워크 demand, \(\mathcal{T}_{N}(t) = \mathcal{T}_{i,1}(t) + \sum_{j=2} \mathcal{T}_{i,j}(t)\)</li>
</ul>

<h3 id="26c-benchmarks">2.6.C Benchmarks</h3>

<ul>
  <li><strong>ES</strong>: 항상 최적의 switching 패턴을 보장. 다른 cell switching 알고리즘의 목적은 이 알고리즘의 근삿값을 달성하는 것이다.</li>
  <li><strong>MLC</strong>: ES에 비해 computation overhead가 적다. QoS를 보장하며 네트워크 규모가 클 때도 사용할 수 있지만 ES 방식에 비해 sub-optimal한 성능을 보인다.</li>
  <li><strong>AAO</strong>: SBS들을 항상 켜 놓는 것으로, 네트워크 QoS를 보장하지만 에너지 절약 보장을 하지 못한다.</li>
</ul>

<p>Q-learning과 같은 강화학습 기반 알고리즘들이 decision making으로 유명하지만 실제 상황에서는 모델 학습이 어렵고 무겁기 때문에 벤치마크 알고리즘에서 제외하였다.</p>

<h3 id="26d-results-and-discussions">2.6.D Results and Discussions</h3>

<p><img src="/assets/img/blog/lightweight-cs/figure.5.png" alt="Figure.5" /></p>

<p>Traffic load의 양이 적을 때 small cell switching의 횟수가 많아지므로 traffic demand가 많을 때 소비 전력이 높고 traffic demand가 적을 때 소비 전력이 작게 된다.</p>

<p>ES 알고리즘을 사용했을 때 모든 경우의 수를 탐색하고 결과를 도출하기 때문에 가장 적은 전력을 소모하게 된다. 하지만 이 방법은 큰 컴퓨팅 소모를 하게 된다.</p>

<p>본 논문에서 제안한 THESIS 알고리즘이 네트워크의 traffic이 높을 때 0.4% 정도의 차이를 보이고, traffic이 낮을 때는 3.5%의 차이를 보임을 확인할 수 있다.</p>

<ul>
  <li>트래픽이 높을 때는 cell을 끌 필요가 많이 없고, 트래픽이 낮을 때 cell을 끌 기회가 많기 때문에 이러한 차이를 보인다.</li>
  <li>트래픽이 높을 때 THESIS와 ES 알고리즘이 거의 비슷한 결과를 보이는 것으로 보아 트래픽이 높을 때는 ES 알고리즘의 high search space라는 장점은 퇴색된다.</li>
</ul>

<p>그림 2(b)에서 ES 알고리즘은 사용되지 않았다. 컴퓨팅 오버헤드가 너무 커서 계산할 수가 없었기 때문이다.</p>

<p><img src="/assets/img/blog/lightweight-cs/figure.6.png" alt="Figure.6" /></p>

<p>최종적으로 위의 그래프에서 각 알고리즘 별 탄소 절감량을 확인할 수 있다. SBS 수가 늘어날수록 탄소 절감량도 늘어나게 되는데, SBS를 끌 수 있는 기회가 많아지기 떄문이다.</p>

<p><img src="/assets/img/blog/lightweight-cs/figure.7.png" alt="Figure.7" /></p>

<p>위의 그래프에서 각 알고리즘의 시간 복잡도를 확인할 수 있다. ES 알고리즘은 SBS의 수가 20개가 넘어가면 기하급수적으로 시간 복잡도가 증가하고, THESIS도 증가하는 추세를 보인다. 하지만 THESIS 알고리즘은 클러스터 내 SBS의 수를 \(B_{th}\)로 제한을 두기 때문에 시간복잡도가 기하급수적으로 증가하는 것을 막을 수 있다.</p>

<h2 id="27-conclusion">2.7 Conclusion</h2>

<p>위에서 볼 수 있듯이 본 논문에서 제안한 THESIS 알고리즘은 획기적인 에너지 절감을 실현시킬 수 있다. 또한 AAO 알고리즘에 비해 탄소 절감을 늘릴 수 있다는 장점도 존재한다. 본 논문의 저자는 future work로 UAV-BS를 이용한 traffic offloading을 제안하였다.</p>

<h1 id="3-take-away">3. Take Away</h1>

<ul>
  <li>Clustering + heuristic 알고리즘을 이용한 lightweight cell switching</li>
  <li>SBS 두 개를 합쳐 MBS로 가정하는 방법으로 HetNet 시뮬레이션</li>
</ul>]]></content><author><name>Geon Kim</name><email>gun@khu.ac.kr</email></author><category term="paper" /><category term="es" /><summary type="html"><![CDATA[**Authors**: Attai Ibrahim Abubakar, Hichael S. Mollel, Metin Ozturk, Sajjad Hussain, and Muhammad Ali Imran]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/lightweight-cs/es.png" /><media:content medium="image" url="http://localhost:4000/assets/img/blog/lightweight-cs/es.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">OpenRAN Gym- AI/ML Development, Data Collection, and Testing for O-RAN on PAWR Platforms</title><link href="http://localhost:4000/blog/paper/2024-05-28-OpenRAN-Gym/" rel="alternate" type="text/html" title="OpenRAN Gym- AI/ML Development, Data Collection, and Testing for O-RAN on PAWR Platforms" /><published>2024-05-28T00:00:00+09:00</published><updated>2024-05-28T00:00:00+09:00</updated><id>http://localhost:4000/blog/paper/OpenRAN-Gym</id><content type="html" xml:base="http://localhost:4000/blog/paper/2024-05-28-OpenRAN-Gym/"><![CDATA[<p class="note" title="Keywords">Open RAN, AI/ML, SDK</p>

<ul id="markdown-toc">
  <li><a href="#1-why-this-paper" id="markdown-toc-1-why-this-paper">1. Why this paper</a></li>
  <li><a href="#2-summary-of-paper" id="markdown-toc-2-summary-of-paper">2. Summary of paper</a>    <ul>
      <li><a href="#21-introduction" id="markdown-toc-21-introduction">2.1 Introduction</a></li>
      <li><a href="#22-openran-gym" id="markdown-toc-22-openran-gym">2.2 OpenRAN Gym</a>        <ul>
          <li><a href="#221-주요-구성요소" id="markdown-toc-221-주요-구성요소">2.2.1 주요 구성요소</a></li>
        </ul>
      </li>
      <li><a href="#23-data-collection-and-control-framework" id="markdown-toc-23-data-collection-and-control-framework">2.3. DATA Collection and Control Framework</a>        <ul>
          <li><a href="#23a-starting-scope" id="markdown-toc-23a-starting-scope">2.3.A <em>Starting SCOPE</em></a></li>
        </ul>
      </li>
      <li><a href="#24-o-ran-control-architecture" id="markdown-toc-24-o-ran-control-architecture">2.4 O-RAN Control Architecture</a>        <ul>
          <li><a href="#24a-starting-the-colo-ran-near-rt-ric" id="markdown-toc-24a-starting-the-colo-ran-near-rt-ric">2.4.A Starting the ColO-RAN Near-RT RIC</a></li>
          <li><a href="#24b-connecting-the-scope-base-station-to-colo-ran" id="markdown-toc-24b-connecting-the-scope-base-station-to-colo-ran">2.4.B Connecting the SCOPE Base Station to ColO-RAN</a></li>
          <li><a href="#24c-initializing-a-sample-xapp" id="markdown-toc-24c-initializing-a-sample-xapp">2.4.C Initializing a Sample xApp</a></li>
        </ul>
      </li>
      <li><a href="#25-xapp-development-workflow-on-colosseum" id="markdown-toc-25-xapp-development-workflow-on-colosseum">2.5 xApp Development Workflow on Colosseum</a>        <ul>
          <li><a href="#25a-example-of-xapps" id="markdown-toc-25a-example-of-xapps">2.5.A Example of xApps</a></li>
        </ul>
      </li>
      <li><a href="#26-traveling-containers" id="markdown-toc-26-traveling-containers">2.6 Traveling Containers</a></li>
      <li><a href="#27-experimental-results" id="markdown-toc-27-experimental-results">2.7 Experimental Results</a>        <ul>
          <li><a href="#27a-results" id="markdown-toc-27a-results">2.7.A Results</a></li>
        </ul>
      </li>
      <li><a href="#28-conclusions" id="markdown-toc-28-conclusions">2.8 Conclusions</a></li>
    </ul>
  </li>
  <li><a href="#3-take-away" id="markdown-toc-3-take-away">3. Take Away</a></li>
</ul>

<h1 id="1-why-this-paper">1. Why this paper</h1>

<ul>
  <li><code class="language-plaintext highlighter-rouge">MaveRIC</code> 시뮬레이터에 쓰일 알고리즘 공부</li>
  <li>RIC에 쓰일 알고리즘 구상에 필요한 프로그램</li>
</ul>

<h1 id="2-summary-of-paper">2. Summary of paper</h1>

<h2 id="21-introduction">2.1 Introduction</h2>
<p><code class="language-plaintext highlighter-rouge">Open RAN</code>은 네트워크 운영자들이 하드웨어 인프라를 교체하지 않고 네트워크 컨디션과 사용자의 요구에 맞춰 맞춤형 서비스를 제공할 수 있게 한다. 또한 하드웨어 교체가 필요없기 때문에 Operational cost를 효과적으로 감소시킬 수 있다.</p>

<p class="note" title="Attention">O-RAN Alliance는 Open RAN을 O-RAN으로 브랜딩하여 표준을 개발중이다.</p>

<p>O-RAN은 두 개의 RAN Intelligent Controller들을 제안하였다.</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">near-RT RIC</code>
    <ul>
      <li>RAN 구성요소들(CUs, DUs)들과 <code class="language-plaintext highlighter-rouge">E2</code> 인터페이스로 연결되어 있으며 10ms와 1s 사이에서 작동하는 control loop들을 담당한다.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">non-RT RIC</code>
    <ul>
      <li>Service Management and Orchestration(SMO) 프레임워크들을 포함하고 있으며 1s보다 큰 시간 스케일에서 작동한다.</li>
      <li>하나 혹은 여러개의 near-RT RIC들과 <code class="language-plaintext highlighter-rouge">A1</code> 인터페이스를 통해 연결되어 있으며 이를 통해 policy들과 네트워크 외부 정보들을 전파시킨다.</li>
      <li>RIC 위에 올라가는 AI/ML 모델을 관리한다.</li>
    </ul>
  </li>
</ol>

<p><code class="language-plaintext highlighter-rouge">SMO</code>는 RAN과 <code class="language-plaintext highlighter-rouge">O1</code> 인터페이스를 통해 연결되며 management와 orchestration을 한다. 또한, virtualization platform(<code class="language-plaintext highlighter-rouge">O-cloud</code>)과 <code class="language-plaintext highlighter-rouge">O2</code> 인터페이스를 통해 연결되어 있다.</p>

<p>AI/ML 알고리즘들을 test/design 하는 것은 다음과 같은 단계들을 포함한다.</p>

<ol>
  <li><strong>Data collection</strong>: AI/ML 모델의 배포될 상황과 다양한 네트워크의 performance indicatos에 맞춰 practical한 dataset을 수집</li>
  <li><strong>AI/ML model design</strong>: 모델의 입/출력을 결정하고, training과 teseting을 결정 후, 성능 평가</li>
  <li><strong>Model deployment</strong>: xApp은 near-RT RIC에 rApp은 non-rt-RIC에 배포</li>
  <li><strong>Model fine-tuning</strong>: RAN의 런타임 데이터에 맞춰 모델을 서로 다른 프로덕션 환경에 적응시킴</li>
  <li><strong>Control, inference and/or forecasting</strong>: RAN을 AI/ML을 통해 제어</li>
</ol>

<p class="note">본 논문에서는 <strong>OpenRAN Gym</strong>(O-RAN 규격을 준수하는 inference와 control AI/ML 알고리즘을 개발하기 위한 오픈소스 toolbox)을 제시하고 있다.</p>

<p>저자는 가장 먼저 OpenRAN Gym의 high-level overview를 제공하고 그 구성요소가 어떻게 data-driven xApp들의 개발, 테스트 workflow들을 실현시키는지 논의한다.</p>

<p>OpenRAN Gym은 end-to-end 디자인, prototyping, testing, 그리고 HetNet 구조에서 실험된 최초의 오픈된, portable한 툴셋이다.</p>

<p><strong>OpenRAN Gym의 contribution</strong>: O-RAN ecosystem에서 AI/ML 솔루션들의 end-to-end 디자인과 테스트를 가능케함</p>

<hr />

<h2 id="22-openran-gym">2.2 OpenRAN Gym</h2>

<h3 id="221-주요-구성요소">2.2.1 주요 구성요소</h3>
<ol>
  <li>공식적, 원격으로 접속 가능한 HetNet 환경에서의 <em>experimental wireless platforms</em>, <code class="language-plaintext highlighter-rouge">Colosseum</code></li>
  <li>Open 프로토콜 스택으로 구현된 <em>softwarized</em> RAN, <code class="language-plaintext highlighter-rouge">srsRAN</code>, <code class="language-plaintext highlighter-rouge">OAI</code></li>
  <li><em>Data collection and control framework</em>, <code class="language-plaintext highlighter-rouge">SCOPE</code></li>
  <li><em>O-RAN control architecture</em>, <code class="language-plaintext highlighter-rouge">ColO-RAN</code></li>
</ol>

<ul>
  <li>Colosseum
    <ul>
      <li>세계에서 가장 큰 네트워크 에뮬레이터. 연구자와 기술자들이 거대한 스케일의 환경에서 연구를 진행할 수 있게 한다.</li>
    </ul>
  </li>
  <li>POWDER
    <ul>
      <li>Salt Lake City에 있는 도시 규모의 wireless tesetbed</li>
    </ul>
  </li>
  <li>COSMOS
    <ul>
      <li>New York City에 있는 도시 규모의 wireless testbed. mmWave 통신과 edge-computing을 중점으로 구현하였다.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/blog/OpenRANgym/article/Figure.1.png" alt="Figure 1. OpenRAN Gym architecture" /></p>

<p>글이 작성된 시점에 OpenRAN Gym은 srsRAN을 이용해 softwarized RAN을 구성하였다. 또한, cellular protocol stack은 SCOPE 프레임워크에 의해 지원되었다. SCOPE를 사용하여 HetNet 환경에서의 데이터 수집을 자동화할 수 있다.</p>

<p>최종적으로, ColO-RAN을 사용해 O-RAN control architecture를 구현하였다. ColO-RAN은 사용자들이 AI/ML 기반 어플리케이션들을 xApp SDK를 사용해 prototype 할 수 있게 한다.</p>

<hr />

<h2 id="23-data-collection-and-control-framework">2.3. DATA Collection and Control Framework</h2>

<p class="note">OpenRAN Gym의 데이터 수집과 control 프레임워크는 SCOPE에 기반한다.</p>

<p>RAN의 런타임에 fine-tune과 데이터 수집을 담당하는 Open API들은 SCOPE에 의해 제공된다.
SCOPE는 실제 실행되고 있는 HetNet 실험환경에서 RAN KPM들을 수집하는 과정을 촉진시킬 수 있다. 결과적으로, SCOPE는 OSC DU에 있는 O-RAN E2 termination을 O-RAN near-RT RIC과 연결해준다.</p>

<h3 id="23a-starting-scope">2.3.A <em>Starting SCOPE</em></h3>
<p>SCOPE는 configuration 파일을 통해 cellular base station들을 작동할 수 있는 Command-line Interface (CLI) tool들을 지원한다.OpenRAN Gym에서 사용하는 주요 파라미터들은 다음과 같다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">network-slicing</code>: base station에서 network slicing을 가능하게 함</li>
  <li><code class="language-plaintext highlighter-rouge">slice-allocation</code>: network slicing이 가능하다면, Resource Block Groups(RBGs)를 세팅하는 파라미터
    <ul>
      <li><strong>예시</strong>: {0:[0, 5], 1:[6, 10]}의 뜻은 RBG 0-5는 slice 0에 6-10은 slice 1에 할당</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">slice-scheduling-policy</code>: 기지국의 network slice에 scheduling policy를 세팅
    <ul>
      <li><strong>예시</strong>: [1, 2]: slice 0에 slicing policy 1울 헐덩, slice 1에 policy 2를 할당(0: round-robin, 1: waterfilling, 2:proportionally fair)</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">slice-users</code>: UE들을 특정 network slice에 associate 시킴.
    <ul>
      <li><strong>예시</strong>: {0:[4, 5], 1:[2, 3]}, UE 4,5를 slice 0, UE 2,3을 slice 1에 associate</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">generic-testbed</code>: SCOPE가 Colloseum 이외의 테스트베드에서 실행되고 있는지 여부를 나타냄</li>
</ul>

<p><code class="language-plaintext highlighter-rouge">SCOPE</code> 구성 파일이 JSON 형식 파일(<em>radio.conf</em>)로 작성된 후 cellular base station, core 네트워크, UE 어플리케이션들은 아래의 커맨드를 통해 시작된다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># !/bin/bash</span>
<span class="nb">cd </span>radio_api/
python3 scope_start.py <span class="nt">--config-file</span> radio.conf
</code></pre></div></div>

<p>런타임 중 RAN으로부터 온 Relevang KPM들은 자동적으로 SCOPE base station들에 로깅된다. KPM 파일들은 CSV 형식으로 저장되고, on-the-fly로도 사용될 수 있다.(AI/ML 모델 훈련). 또한 experiment가 끝나고 offline으로도 회수되어 사용할 수 있다.</p>

<h2 id="24-o-ran-control-architecture">2.4 O-RAN Control Architecture</h2>
<p>OpenRAN GYM에서 사용하는 O-RAN control architecture는 ColO-RAN에 기반한다. 이 프레임워크는 OSC near-RT RIC의 lightweight 구현을 제공한다. Colosseum 시스템에서 standalone Docker 컨테이너로 구현되기 때문이다.</p>

<p>ColO-RAN의 high level 다이어그램은 아래의 그림과 같다. 
<img src="/assets/img/blog/OpenRANgym/article/Figure.2.png" alt="Figure 2. ColO-RAN xApp" /></p>

<p>ColO-RAN xApp은 두개의 주 구성요소로 이루어져있다,</p>

<ul>
  <li><em>Service Model(SM) Connector</em>: xApp과 near-RT RIC 사이의 메세지들을 관리</li>
  <li><em>Data-driven logic unit</em>: RAN base station들로부터 받은 KPM들은 처리하고 AI/ML 모델들로부터 받은 과제 수행
    <ul>
      <li><strong>AI/ML model</strong>: 특정 data-driven model로 구성(예, DRL agent, DNN 등)</li>
      <li><strong>Data processing module</strong>: KPM 데이터들을 AI/ML 모델이 사용할 수 있는 데이터 형식으로 변환</li>
    </ul>
  </li>
</ul>

<h3 id="24a-starting-the-colo-ran-near-rt-ric">2.4.A Starting the ColO-RAN Near-RT RIC</h3>
<p>ColO-RAN의 near-RT RIC은 <code class="language-plaintext highlighter-rouge">setup-ric.sh</code>를 이용하여 docker 컨테이너로 빌드될 수 있다. 이 스크립트를 이용해 RIC은 RAN으로부터 메세지를 받고 교환할 수 있다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">cd </span>setup-scripts/
./setup-ric.sh col0
</code></pre></div></div>

<p>ColO-RAN near-RT RIC의 이미지들은 다음과 같은 항목들을 포함한다.</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">e2term</code>: RIC E2 메세지의 종단점</li>
  <li><code class="language-plaintext highlighter-rouge">e2mgr</code>: E2 인터페이스로 송/수신되는 메시지들을 관리</li>
  <li><code class="language-plaintext highlighter-rouge">e2rtmansim</code>: RIC 안에서 RIC Message Router(RMR) 프로토콜을 사용하여 E2 메시지들을 라우팅</li>
  <li><code class="language-plaintext highlighter-rouge">db</code>: Redis 데이터베이스를 이용해 RIC에 연결된 RAN 노드들의 기록을 저장</li>
</ol>

<p>Docker 이미지 빌드 후, E2 termination 종단점을 통해 다가올 연결을 listening하는 RIC 컨테이너들이 생성된다.</p>

<h3 id="24b-connecting-the-scope-base-station-to-colo-ran">2.4.B Connecting the SCOPE Base Station to ColO-RAN</h3>

<p>위의 과정을 통해 ColO-RAN이 세팅되고 시작된 후, cellular base station은 O-RAN E2 termination을 통해 연결될 수 있다. RAN-side E2 termination은 아래의 목적들로 사용될 수 있는데</p>
<ol>
  <li>xApp들로부터 <em>RIC Subscription</em> 수신</li>
  <li><em>RIC Indication</em> 메세지를 통해 xApp들에게 주기적으로 KPM reports를 송신</li>
  <li>xApp들로부터 받은 control message들에 기반해 base station들의 런타임 동안 configuration을 수정</li>
</ol>

<p>SCOPE base station의 E2 termination을 초기화하는 커맨드는 다음과 같다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">cd </span>colosseum-scope-e2/
./build_odu.sh clean
./run_odu.sh
</code></pre></div></div>
<ul>
  <li><code class="language-plaintext highlighter-rouge">build_odu.sh</code>: near-RT RIC이 연결할 IP 주소와 포트를 특정</li>
  <li><code class="language-plaintext highlighter-rouge">run_odu.sh</code>: E2 termination 프로세스 실행, base station과 near-RT RIC 연결</li>
</ul>

<p>연결이 성공적으로 수행되었다면 <code class="language-plaintext highlighter-rouge">docker logs -f e2term</code> 커맨드를 통해 확인할 수 있다.</p>

<h3 id="24c-initializing-a-sample-xapp">2.4.C Initializing a Sample xApp</h3>

<p>SCOPE base station이 near-RT RIC에 연결된 후, xApp들은 시작될 수 있다. 본 논문에서는 xApp 디자인을 장려하기 위해 <code class="language-plaintext highlighter-rouge">ready-to-use sample xApp</code> 템플릿을 제공하고 있다. 이 템플릿에 연구자들은 AI/ML 모델을 plug-in 하기만 하면 된다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">cd </span>setup-scripts/
./setup-sample-xapp.sh gnb:&lt;example&gt;
</code></pre></div></div>

<p>xApp이 구독해야하는 base station의 식별자를 커맨드에 입력한다. 그 후 sample xApp의 Docker 이미지를 빌드한다. 스크립트는 near-RT RIC에서 sample-xApp이라는 xApp Docker 컨테이너를 시작한다.</p>

<p>컨테이너 시작 후, xApp 프로세스들은 아래의 커맨드들을 통해 실행된다.</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
docker <span class="nb">exec</span> <span class="nt">-it</span> sample-xapp /home/sample-xapp/run_xapp.sh
</code></pre></div></div>

<p>위의 커맨드는 targeted RAN 노드들에 RIC Subscription 메시지, 주기적인 RAN KPMs reports를 통해 xApp subscription을 유발한다.</p>

<h2 id="25-xapp-development-workflow-on-colosseum">2.5 xApp Development Workflow on Colosseum</h2>

<p>Open RAN Gym on Colosseum을 사용해 Data-driven xApp을 개발하는 과정은 아래의 그림과 같이 나타낼 수 있다.</p>

<p><img src="/assets/img/blog/OpenRANgym/article/Figure.3.png" alt="OpenRAN Gym xApp Design and testing workflow on Colosseum" /></p>

<ol>
  <li>
    <p><strong>Data collection</strong></p>

    <p>xApp에 임베드 되어있는 AI/ML 모델을 train/test하기 위한 데이터 수집</p>
  </li>
  <li>
    <p><strong>Model design, training and testing</strong></p>

    <p>AI/ML 모델이 사용할 알고리즘 선택, input으로 사용할 데이터 선택, output 액션들의 집합 설정을 포함한다. 디자인 phase 이후, offline으로 모델은 학습되고 테스트된다.</p>
  </li>
  <li>
    <p><strong>Deploy the model as an xApp</strong></p>

    <p>모델 test 후, ColO-RAN near-RT RIC의 xApp으로 배포된다. 정확하게는 AI/ML 모델은 ColO-RAN xApp의 <em>data-driven logic unit</em>에 포함된다.</p>
  </li>
  <li>
    <p><strong>Online model fine-tuning</strong></p>

    <p class="note">런타임 중, xApp은 near-RT RIC과 E2 termination을 이용하여 SCOPE base station과 통신한다.</p>

    <p>이를 달성하기 위해 다음과 같은 과정을 거친다.</p>
    <ol>
      <li>xApp은 RIC Subscription 메세지를 보내 base station을 subscribe 한다.</li>
      <li>주기적인 KPMs reports를 trigger 한다.</li>
      <li>Reports는 RIC Indication 메세지를 통해 전송되고, xApp에서 model을 online으로 fine-tune 하기 위해 사용된다.</li>
    </ol>
  </li>
  <li>
    <p><strong>Perform RAN control/inference</strong></p>

    <p>이 단계에서 xApp은 RAN에 inference와 control을 실행하는 live 인프라로 사용된다. xApp은 model에 의해 계산된 action을 SCOPE base station에게 RIC Control messages를 통해 전송한다.</p>
  </li>
</ol>

<h3 id="25a-example-of-xapps">2.5.A Example of xApps</h3>

<p>본 논문에서 제시하고 있는 xApp들은 Colosseum 네트워크 emulator 환경에서 7개의 base station과 42개의 UE들을 사용한 것이다. 각각의 base station들은 SCOPE를 통해 구현되었고, 6개의 UE를 서비스하고 있으며 UE들은 다른 traffic 요구조건을 가지고 있다.</p>

<p>UE들의 트래픽은 두 가지 종류로 나뉜다.</p>
<ol>
  <li>Time-sensitive(URLLC)</li>
  <li>Broadband(eMBB, MTC)</li>
</ol>

<p><img src="/assets/img/blog/OpenRANgym/article/Figure.4.png" alt="Figure 4" /></p>

<p>위의 그림은 본 논문에서 사용한 xApp의 구조이다.</p>

<ul>
  <li><strong>Data-driven logic unit</strong>
    <ul>
      <li><strong>Encoder</strong>: 데이터의 차원을 줄이는 역할, E2 인터페이스로 KPM reports를 수신</li>
      <li><strong>DRL agent</strong>: 수신받은 정보를 네트워크 상태로 바꾸고 최적화 하는 역할</li>
    </ul>
  </li>
</ul>

<ol>
  <li>
    <p><strong>Agent Design</strong></p>

    <p>DRL Agent는 Actor-critic 기반 구조의 <em>Proximal Policy Optimization(PPO)</em>로 구현된다. Actor와 Critic 모두 5 layer로 구성되며, 각 layer는 30개의 neuron을 가지고 있다.</p>
  </li>
  <li>
    <p><strong>Actions</strong></p>

    <p>본 논문에서는 서로 다른 두가지 xApp을 훈련시켜 네트워크 최적화 성능을 비교하였다.</p>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">sched</code>: 스케쥴링 정책(round robin, waterfall 등(만 제어</li>
      <li><code class="language-plaintext highlighter-rouge">sched-slicing</code>: 스케쥴링 정책 뿐 아니라 각 slice에 할당되는 자원들도 제어</li>
    </ul>
  </li>
  <li>
    <p><strong>Reward</strong></p>

    <p>두 xApp 모두 broadband traffic 클래스에서 전송되는 데이터를 최대화하고, time-sensitive traffic 클래스에선 end-to-end latency를 최소화하는 것을 목적으로 하였다.
 기지국의 데이터에서 직접적으로 end-to-end system latency를 명시하는 항목이 존재하지 않으므로 buffer occupancy 수치를 latency 기준으로 삼았다.</p>
    <ul>
      <li>Buffer occupancy: 각 패킷이 전송 buffer 큐에서 얼마나 시간을 보내는지 측정</li>
    </ul>

    <p>위에서 언급한 기준들을 reward에 반영하기 위해, throughput 최대화와 downlink buffer size를 최소화하는 것이 reward 함수에 반영되어 있다.</p>
  </li>
</ol>

<p><img src="/assets/img/blog/OpenRANgym/article/Figure.5.png" alt="Figure 5" /></p>

<p><code class="language-plaintext highlighter-rouge">sched-slicing</code> xApp이 더 좋은 성능을 보임을 그래프에서 확인할 수 있다.</p>

<h2 id="26-traveling-containers">2.6 Traveling Containers</h2>

<p>본 섹션에서는 컨테이너화 된 OpenRAN Gym이 어떻게 다른 testbed로 전송되는지 설명한다.<em>traveling OpenRAN Gym containers</em>의 구현 때문에 상당한 노력이 들었다고 한다.</p>

<p>후속 연구자들의 수고를 줄이기 위해 저자는 OpenRAN Gym LXC 컨테이너들을 개발하였다. 실행하고자 하는 testbed에서 LXC 이미지가 전송된 후, 아래의 커맨드를 입력하여 이미지가 import 된다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Listing 6</span>
lxc image import scope-with-e2.tar.gz <span class="nt">--alias</span> scope-e2
</code></pre></div></div>

<p>커맨드 입력 후 <code class="language-plaintext highlighter-rouge">scope</code>라는 이미지가 실행된다.</p>

<p>ColO-RAN의 경우, RIC과 ColO-RAN 컨테이너 간 메시지들이 직접적으로 통신되기 위해 Network Address Translation(NAT) 규칙들을 구성하는 것이 필수적이다.</p>

<p>위에서 설명한 과정들을 자동화하기 위해 저자는 스크립트 파일들을 오픈 소스로 제공하고 있다. 스크립트 파일들은 아래와 같은 과정들을 포함한다.</p>
<ol>
  <li>컨테이너에게 정확한 radio interface 전달</li>
  <li>컨테이너에게 적절한 권한 부여</li>
  <li>호스트 머신의 NAT 규칙들 세팅</li>
  <li>Importing 된 이미지로부터 OpenRAN Gym LXC 컨테이너들 시작</li>
</ol>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Listing 9</span>
./start-lxc-scope.sh testbed usrp-type <span class="o">[</span>flash]
</code></pre></div></div>
<p class="note">SCOPE LXC 컨테이너를 생성, 세팅, 시작하는 스크립트 파일을 실행하는 커맨드</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Listing 10</span>
./start-lxc-ric.sh
</code></pre></div></div>
<p class="note"><code class="language-plaintext highlighter-rouge">Listing 6</code>에서 생성된 이미지로부터 SCOPE LXC 컨테이너를 생성, 세팅, 실행하는 커맨드</p>

<h2 id="27-experimental-results">2.7 Experimental Results</h2>

<p>이 섹션에서는 작동중인 HetNet에서 작동죽인 OpenRAN Gym에서 실행한 시뮬레이션 결과들을 설명한다.</p>

<p>공정한 비교를 위해 각 테스트베드마다 1개의 cellular base station과 3개의 UE, 1개의 near-RT RIC 노드만을 가지고 시뮬레이션을 진행하였다.</p>

<p>iPerf3 툴에 의해 생성된 Downlink User Datagram Protocol(UDP) 트래픽을 이용하여 네트워크 성능을 평가하였다.</p>

<h3 id="27a-results">2.7.A Results</h3>

<p><img src="/assets/img/blog/OpenRANgym/article/Figure.6,7.png" alt="Figure 6,7" />
<img src="/assets/img/blog/OpenRANgym/article/Table 2.png" alt="Table 2" /></p>

<p>Figure 6과 7은 각 network slicing마다 RBG들이 다르게 할당되었을 때 전체 네트워크 throughput을 보여준다. 시뮬레이션 결과를 통해 다양한 테스트베드에서 throughput이 다를지라도, 전체적인 추세는 비슷하다는 것을 알 수 있다.</p>

<p>아래의 그림은 SCOPE를 통해 ColO-RAN near-RT RIC이 소프트웨어화 된 RAN을 control하는 것을 구현한 결과이다.
<img src="/assets/img/blog/OpenRANgym/article/Figure 8.png" alt="Figure 8" /></p>

<p>Baseline은 RIC에 의한 제어가 없을 때로 설정하였고, 150초마다 xApp이 특정 network slice를 선호하도록 설정하였다.</p>

<p>O-RAN RAN slicing SM에 의해 각 slice에만 할당된 RBG의 수를 런타임에 재구성하여 수행되며, 해당 slice에 속한 사용자의 transmission을 예약할 수 있다.</p>

<h2 id="28-conclusions">2.8 Conclusions</h2>

<p>본 논문에서는 최초의 publicly-available research 픒랫폼인 OpenRAN Gym을 소개하였다. 또한 다양한 스케일의 테스트베드에서 시뮬레이션을 진행하며 결과를 제시하였고, 많은 연구자들의 사용을 권장한다.</p>

<h1 id="3-take-away">3. Take Away</h1>

<ul>
  <li>OpenRAN Gym 사용 커맨드를 꼭 기억하여 MaveRIC 시뮬레이터에 사용할 것</li>
  <li>Container 환경에서 시뮬레이션이 진행된다는 것을 기억</li>
  <li>HetNet 환경의 에뮬리에션이 가능함</li>
</ul>]]></content><author><name>Geon Kim</name><email>gun@khu.ac.kr</email></author><category term="paper" /><category term="ieee" /><category term="o-ran" /><summary type="html"><![CDATA[**Authors**: Leonardo Bonati, Michele Polese, Salvatore D'Oro, Stefano Basagni, Tommaso Melodia]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/img/blog/OpenRANgym/thumbnail.jpeg" /><media:content medium="image" url="http://localhost:4000/assets/img/blog/OpenRANgym/thumbnail.jpeg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>